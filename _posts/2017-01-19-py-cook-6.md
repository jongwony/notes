---
layout: post
title: Python cookbook Chapter 6 한글
tags: ['python', 'docs', 'csv', 'json', '한글']
progress: 38
---

<div id='index-table'>
<h2>6. Data Encoding and Processing</h2>
</div>

- - -


<div class='warn'>
이 문서는 Python Coobook 3rd edition - O'REILLY, David Beazley & Brian K. jones 를 참고한 것이며 개인적인 번역으로 인한 오역이 있을 수 있습니다.<br> <a href="//wikidocs.net/book/1">Python을 완전히 처음 접하는 경우</a>에는 적합하지 않습니다.<br>
</div>

이 챕터의 메인 포커스는 Python을 사용하여 `CSV` 파일, `JSON`, `XML` 및 바이너리 압축 레코드 같은 여러 종류의 일반적인 인코딩으로 존재한 데이터를 처리하는 것입니다.
데이터 구조 챕터와는 달리 이 챕터는 특정 알고리즘에 초점을 두진 않는 대신 프로그램 외부에서 데이터를 가져오는 문제에 초점을 맞춥니다.

## 6.1. Reading and Writing CSV Data

#### Problem

`CSV` 파일로 인코딩된 데이터를 읽고 쓰길 원합니다.

#### Solution

대부분의 `CSV` 데이터는 `csv` 라이브러리를 사용합니다.
예를 들어 `stocks.csv`라는 이름의 주식 데이터 파일이 있다고 가정합니다.

```
Symbol,Price,Date,Time,Change,Volume
"AA",39,48,"6/11/2007","9:36am",-0.18,181800
"AIG",71,38,"6/11/2007","9:36am",-0.15,195500
"AXP",62,58,"6/11/2007","9:36am",-0.46,935000
"BA",98,31,"6/11/2007","9:36am",+0.12,104800
"C",53,08,"6/11/2007","9:36am",-0.25,360900
"CAT",78,29,"6/11/2007","9:36am",-0.23,225400
```

일련의 `tuple`로 데이터를 읽는 방법은 다음과 같습니다.

```python
import csv
with open('stocks.csv') as f:
    f_csv = csv.reader(f)
    headers = next(f_csv)
    for row in f_csv:
        # Process row
        ...
```

앞의 코드에서 `row`는 `tuple`이 됩니다. 그러므로 특정 필드에 액세스하기 위해서는 `row[0](Symbol)` 및 `row[4](Change)`와 같은 `indexing`을 사용해야 될 수 있습니다.

몇몇 `indexing`이 종종 혼란스러울 수 있기 때문에 `namedtuple` 사용을 고려해야 할 부분이 여기 있습니다.

```python
from collections import namedtuple
with open('stocks.csv') as f:
    f_csv = csv.reader(f)
    headings = next(f_csv)
    Row = namedtuple('Row', headings)
    for r in f_csv:
        row = Row(*r)
        # Process row
        ...
```

이렇게 하면 인덱스 대신 `row.Symbol` 및 `row.Change`와 같은 열 헤더를 사용할 수 있게 됩니다. 이 작업은 컬럼 헤더가 유효한 Python 식별자인 경우에만 동작한다는 점에 유의해야합니다. 그렇지 않으면 처음 헤더를 `massage`할 수도 있습니다.(예. 비식별문자를 밑줄 또는 유사한 문자로 바꾸는 것)

다른 대안은 데이터를 일련의 `dictionary`로 대신 읽는 것입니다.

```python
import csv
with open('stocks.csv') as f:
    f_csv = csv.DictReader(f)
    for row in f_csv:
        # process row
        ...
```

이 버전에서, 행 헤더를 사용하여 각 행의 요소에 액세스합니다. 예를 들어 `row['Symbol']` 또는 `row['Change']`와 같이 액세스합니다.

`CSV` 데이터를 작성하기 위해서도 `csv` 모듈을 사용할 수 있지만 객체를 생성해야합니다.

```python
headers = ['Symbol', 'Price', 'Data', 'Time', 'Change', 'Volume']
rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),
    ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),
    ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)]

with open('stocks.csv', 'w') as f:
    f_csv = csv.writer(f)
    f_csv.writerow(headers)
    f_csv.writerows(rows)
```

만약 일련의 `dictionary`가 있다면 다음을 수행합니다.

```python
headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']
rows =  [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.18, 'Volume':181800},
{'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007','Time':'9:36am', 'Change':-0.15, 'Volume': 195500},
{'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',
 'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},
]

with open('stocks.csv', 'w') as f:
    f_csv = csv.DictWriter(f, headers)
    f_csv.writeheader()
    f_csv.writerows(rows)
```

#### Discussion

거의 매번 수동으로 `CSV` 데이터를 `split` 하고 `parse`하려는 것 보다 `csv` 모듈을 사용하는 것을 선호해야 합니다. 예를 들어 코드를 이렇게 작성할 수도 있을 것입니다.

```python
with open('stocks.csv') as f:
    for line in f:
        row = line.split(',')
        # process.row
        ...
```

이런 접근법의 문제는 여전히 불쾌한 세부사항을 다루어야 한다는 것입니다.
예를 들어 필드 중 하나라도 따옴표로 묶인 경우 따옴표를 `strip`해야 합니다. 추가로 따옴표로 묶인 필드가 콤마를 포함하는 일이 일어난다면 잘못된 크기의 행을 생성하고 코드가 중단됩니다.

기본적으로 `csv` 라이브러리는 `Microsoft Excel`에서 사용되는 `CSV` 인코딩 규칙을 바탕으로 프로그래밍 되어 있습니다.
이는 아마도 가장 일반적인 변형이며 최고의 호환성을 제공할 것입니다.
하지만 `csv`를 위한 문서를 참조하면 다양한 `format`으로 인코딩을 조정할 수 있는 몇가지 방법을 볼 수 있습니다.(구분문자 변경 등) 예를 들어 `tab-delimited` 데이터로 대신 읽고 싶으면 다음을 사용합니다.

```python
# Example of reading tab-separated values
with open('stocks.csv') as f:
    f_tsv = csv.reader(f, delimiter='\t')
    for row in f_tsv
    # Process row
    ...
```

`CSV` 데이터를 읽어서 `namedtuple`로 변환하려면 컬럼 헤더 유효성을 약간 조심해야 할 필요가 있습니다. 예를 들어 `CSV` 파일이 헤더 라인이 유효하지 않은 식별자를 포함한다면

```
Street Address,Num-Premises,Latitude,Longitude
5412 N CLARK,10,41.980262,-87.668452
```

이는 실제로 `namedtuple` 의 생성으로 `ValueError` 예외를 유발하게 됩니다.
이를 해결하려면 먼저 헤더를 `scrub` 해야 할 수도 있습니다. 예를 들어 `regex` 대체로 유효하지 않은 식별자를 다음과 같이 다룹니다.

```python
import re
with open('stocks.csv') as f:
    f_csv = csv.reader(f)
    headers = [re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv)]
    Row = namedtuple('Row', headers)
    for r in f_csv:
        row = Row(*r)
        # Process row
        ...
```

또한 `csv`가 데이터를 해석하거나 문자열이 아닌 다른 `type`으로 변환하려고 시도하지 않는다는 점을 강조하는 것이 중요합니다.
이런 변환이 중요하다면 이는 스스로 해야 할 일입니다.
다음은 `CSV` 데이터에서 추가 `type` 변환을 수행하는 한가지 예입니다.

```python
col_types = [str, float, str, str, float, int]
with open('stocks.csv') as f:
    f_csv = csv.reader(f)
    headers = next(f_csv)
    for row in f_csv:
        # Apply conversions to the row items
        row = tuple(convert(value) for convert, value in zip(col_types, row))
        ...
```

대안으로 다음은 `dictionary`의 필드를 변환하는 예제입니다.

```python
print('Reading as dicts with type conversion')
field_types = [('Price', float), ('Change', float), ('Volume', int)]

with open('stocks.csv') as f:
    for row in csv.DictReader(f):
        row.update((key, conversion(row[key])) for key, conversion in field_types)
        print(row)
```

일반적으로 이러한 변환에 조금 주의를 하는 것이 좋습니다. 실제로는 `CSV` 파일에 누락된 값, 손상된 데이터, `type` 변환을 깰 수 있는 여러 문제가 있는것이 일반적입니다.
그러므로 데이터에 오류가 없다는 것이 보증되지 않는 한 고려해봐야 할 사항입니다.(적절한 예외 핸들링을 추가해야 할 것입니다.)

마지막으로 `CSV` 데이터를 읽는 목적이 데이터 분석 및 통계를 수행하는 것이라면 [Pandas package](//pandas.pydata.org/)를 살펴볼 수 있습니다. `Pandas`는 `CSV` 데이터를 `DataFrame` 객체로 로드하는 편리한 `pandas.read_csv()` 함수를 포함합니다. 거기서 다양한 요약 통계를 생성하고 데이터를 필터링하며 다른 종류의 높은 레벨의 작업을 수행할 수 있습니다. [6.13장](#613-summarizing-data-and-performing-statics)에 예가 주어져 있습니다.

## 6.2. Reading and Writing JSON Data

#### Problem

`JSON(JavaScript Object Notation)`으로 인코딩된 데이터를 읽고 쓰길 원합니다.

#### Solution

`json`모듈은 `JSON`의 데이터를 인코딩과 디코딩 하기위한 쉬운 방법을 제공합니다. `json.dump()`와 `json.loads()` 두 메인 함수가 있으며, `pickle`과 같은 시리얼라이즈하는 라이브러리에서 사용되는 인터페이스를 미러링합니다. 다음은 Python 데이터 구조를 `JSON`으로 변환하는 방법입니다.

```python
import json
data = {
    'name' : 'ACME'
    'shares' : 100,
    'price' : 542.23
}
json_str = json.dumps(data)
```

다음은 `JSON` 인코딩된 문자열을 Python 데이터 구조로 되돌리는 방법입니다.

```python
data = json.loads(json_str)
```

문자열 대신 파일을 사용하는 경우 `JSON` 데이터를 인코딩하고 디코딩하기 위해 대안으로 `json.dump()`와 `json.load()`를 사용할 수 있습니다.

```python
# Writing JSON data
with open('data.json', 'w') as f:
    json.dump(data, f)

# Reading data back
with open('data.json', 'r') as f:
    data = json.load(f)
```

#### Discussion

`JSON` 인코딩은 기본 `None`, `bool`, `int`, `float`, `str` `type` 뿐만 아니라 이런 `type`을 포함하는 `list`, `tuple`, `dictionary`도 지원합니다.
`dictionary`의 경우 `key`는 문자열로 간주됩니다.(`dictionary`의 어떠한 문자열이 아닌 `key`라도 인코딩할 때 문자열로 변환됩니다.)
`JSON` 사양을 준수하려면 Python `list`와 `dictionary` 만을 인코딩 해야 합니다. 게다가 웹 애플리케이션에서는 최상위 객체가 `dictionary`가 되는 것이 표준적인 일입니다.

`JSON` 인코딩의 `format`은 몇가지 사소한 변경 사항을 제외하고는 거의 Python 문법과 동일합니다.
예를 들어 `True`는 `true`로, `False`는 `false`로, `None`은 `null`로 매핑됩니다.

```python
>>> json.dumps(False)
'false'
>>> d = {'a': True, 'b': 'Hello', 'c': None}
>>> json.dumps(d)
'{"b": "Hello", "c": null, "a": true}'
```

`JSON`에서 디코딩 된 데이터를 검사하려는 경우, 특히 데이터가 중첩 구조나 필드의 깊은 레벨을 포함할 경우에 데이터를 출력하여 구조를 확인하는 것이 어려울 수 있습니다.
이를 위해 `pprint` 모듈에서 `pprint()` 함수를 사용하는 것을 고려하시기 바랍니다. 이는 `key`를 알파벳화 시키고 `dictionary` 역시 보다 정상적인 방법으로 출력할 수 있습니다. 다음은 트위치의 검색 결과를 멋지게 출력하는 방법을 설명하는 예제입니다.

```python
from urllib.request import urlopen
import json
u = urlopen('http://search.twitter.com/search.json?q=python&rpp=5')
resp = json.loads(u.load().decode('utf-8'))

from pprint import pprint
pprint(resp)
'''
{'completed_in': 0.074,
 'max_id': 264043230692245504,
 'max_id_str': '264043230692245504',
 'next_page': '?page=2&max_id=264043230692245504&q=python&rpp=5',
 'page': 1,
 'query': 'python',
 'refresh_url': '?since_id=264043230692245504&q=python',
 'results': [{'created_at': 'Thu, 01 Nov 2012 16:36:26 +0000',
              'from_user': ...
             },
             {'created_at': 'Thu, 01 Nov 2012 16:36:14 +0000',
              'from_user': ...
             },
             {'created_at': 'Thu, 01 Nov 2012 16:36:13 +0000',
              'from_user': ...
             },
             {'created_at': 'Thu, 01 Nov 2012 16:36:07 +0000',
              'from_user': ...
             }
             {'created_at': 'Thu, 01 Nov 2012 16:36:04 +0000',
              'from_user': ...
             }],
 'results_per_page': 5,
 'since_id': 0,
 'since_id_str': '0'}
'''
```

일반적으로 `JSON` 디코딩은 제공된 데이터로부터 `dict` 또는 `list`를 생성할 것입니다.
만일 다른 종류의 객체를 생성하고 싶다면 `object_pairs_hook` 또는 `object_hook` 을 `json.load()`에 제공하시기 바랍니다. 예를 들어 `JSON` 데이터를 디코딩하는 방법과 `OrderDict` 의 순서를 보존하는 방법입니다.

```python
s = '{"name": "ACME", "shares": 50, "price": 490.1}'
from collections import OrderedDict
data = json.loads(s, object_pairs_hook=OrderedDict)
```

다음은 `JSON dictionary`를 Python 객체로 변환하는 방법입니다.

```python
class JSONObject:
    def __init__(self, d):
        self.__dict__ = d

data = json.loads(s, object_hook=JSONObject)
print(data.name, data.shares, data.price)
```

마지막 예제는 `JSON` 데이터 디코딩으로 생성된 `dictionary`가 `__init__()`에 단일 인수로 전달된 것입니다. 거기서 객체의 인스턴스 `dictionary`로 직접 사용하는 것과 같이 원하는 대로 자유롭게 사용할 수 있습니다.

`JSON` 인코딩에 유용한 몇가지 옵션이 있습니다.
멋진 `format`으로 출력하고 싶으면 `indent` 인수를 `json.dumps()`에 사용할 수 있습니다.
이로 인해 출력이 `pprint()` 함수와 비슷하게 출력됩니다.

```python
>>> print(json.dumps(data))
{"price": 542.23, "name": "ACME", "shares": 100}
>>> print(json.dumps(data, indent=4))
{
    "price": 542.23,
    "name": "ACME",
    "shares": 100
}
```

출력에 `key`를 정렬시키길 원한다면 `sort_keys` 인수를 사용하면 됩니다.

```python
>>> print(json.dumps(data, sort_keys=True))
{"name": "ACME", "price": 542.23, "shares": 100}
```

인스턴스는 일반적으로 `JSON`으로 시리얼라이즈 할 수 없습니다.

```python
class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y

p = Point(2, 3)
json.dumps(p)

TypeError: ... is not JSON serializable
```

인스턴스를 시리얼라이즈 하려면 인스턴스를 입력으로 사용하고 시리얼라이즈 할 수 있는 `dictionary`를 반환하는 함수를 제공할 수 있습니다.

```python
def serialize_instance(obj):
    d = {'__classname__' : type(obj).__name__}
    d.update(vars(obj))
    return d
```

인스턴스를 다시 가져오려면 다음과 같은 코드를 작성할 수 있습니다.

```python
# Dictionary mapping names to konwn classes
classes = {
    'Point' : Point
}

def unserialize_object(d):
    clsname = d.pop('__classname__', None)
    if clsname:
        cls = classes[clsname]
        obj = cls.__new__(cls)      # Make instance without calling __init__
        for key, value in d.items():
            setattr(obj, key, value)
            return obj
    else:
        return d
```

다음은 이 함수들이 사용되는 방법의 예제입니다.

```python
p = Point(2, 3)
s = json.dumps(p, default=serialize_instance)
a = json.loads(p, object_hook=unserialize_object)
print(a.x, a.y)
# 2 3
```

`json` 모듈에 낮은 레벨의 숫자나 `NaN` 같은 특별한 값 등등 다른 다양한 옵션이 있습니다. 세부 사항은 [문서](//docs.python.org/3/library/json.html)를 참고하시기 바랍니다.

- - -

<div class='def'>
XML 데이터를 다루는 부분은 추후에 추가할 예정입니다.
</div>

- - -

## 6.8. Interacting with a Relational Database

#### Problem

관계 데이터베이스에 `select`, `insert`, `delete`를 해야 합니다.

#### Solution

Python에서 데이터의 열을 나타내는 표준적인 방법은 일련의 `tuple`로써 나타내는 것입니다.

```python
stocks = [
    ('GOOG', 100, 490.1),
    ('AAPL', 50, 545.75),
    ('FB', 150, 7.45),
    ('HPQ', 75, 33.2),
]
```

이 형테로 데이터가 주어지면 [PEP 249](//www.python.org/dev/peps/pep-0249)에 설명된 것처럼 Python의 표준 데이터베이스 `API`를 사용하여 관계 데이터베이스와 상호작용하는 것이 비교적 간단합니다. `API`의 요지는 데이터베이스에 대한 모든 작업이 `SQL` 쿼리에 의해 수행된다는 것입니다. 각 입력 또는 출력 데이터의 열은 `tuple`로 표현됩니다.

설명을 위해 Python과 함께 제공되는 `sqlite3` 모듈을 사용할 수 있습니다. 다른 `MySql`, `Postgres`, `ODBC` 데이터베이스를 사용한다면 서드파티 모듈을 설치해야 합니다. 하지만 기본적인 프로그래밍 인터페이스는 완전히 동일하지는 않아도 사실상 동일할 것입니다.

첫 번쨰 단계는 데이터베이스에 연결하는 것입니다. 일반적으로 `connect()` 함수를 실행하며, 데이터베이스 이름, `hostname`, `username`, `password`, 필요하다면 다른 세부사항의 파라미터를 제공합니다.

```python
import sqlite3
db = sqlite3.connect('database.db')
```

데이터로 무언가 하기 위해서는 다음에 커서를 생성합니다. 커서를 한번 생성하변 `SQL` 쿼리 실행을 시작할 수 있습니다.

```python
c = db.cursor()
c.execute('create table portfolio (symbol text, shares integer, price real)')
db.commit()
```

일련의 열을 데이터에 `insert`하려면 다음과 같은 문장을 사용합니다.

```python
c.executemany('insert into portfolio values (?,?,?)', stocks)
db.commit()
```

쿼리를 실행하려면 다음과 같은 문장을 사용할 수 있습니다.

```python
for row in db.execute('select * from portfolio'):
    print(row)
```

사용자가 입력한 파라미터를 받아들이는 쿼리를 수행하려면 다음과 같이 `?`을 사용하는 파라미터를 `escape` 해야 합니다.

```python
min_price = 100
for row in db_execute('select * from portfolio where price >= ?', (min_price,)):
    print(row)
```

#### Discussion

낮은 레벨에서 데이터베이스와 상호작용하는 것은 매우 간단한 일입니다.
데이터베이스를 갱신하거나 데이터를 검색하는 간단한 형태의 `SQL`문을 작성하여 기본 모듈에 제공하면 됩니다.
즉 여전히 `case-by-case`로 정리 해야 할 까다로운 세부사항도 있습니다.

하나 복잡한 점은 데이터베이스에서 Python `type`으로의 데이터 매핑입니다.
`date` 같은 항목의 경우 `datetime` 모듈에서 사용된 `datetime` 인스턴스를 사용하는 것이나 `time` 모듈에서 사용되는 시스템 `timestamp`를 사용하는 것이 대부분 일반적입니다.
숫자 데이터나 특히 소수 데이터가 포함된 금융 데이터의 경우 `decimal` 모듈의 `Decimal` 인스턴스로 표현될 수 있습니다.
불행히도 정확한 매핑은 데이터베이스 `backend`에 따라 다르므로 관련 문서를 읽어야 합니다.

또 다른 매우 중대한 복잡한 점은 `SQL`문의 문자열 `format`과 관련이 있습니다. **절대 문자열을 생성하기 위한 Python의 `formatting` 연산자(예. `%`)나  `.format()` 메서드를 사용해서는 안됩니다.** 만일 이런 `formatting` 연산자가 제공되는 값들이 유저 입력에서 나온다면 프로그램이 `SQL-injection` 공격에 노출됩니다.([http://xkcd.com/327](//xkcd.com/327/) 참조)
쿼리에서 특별한 `?` 와일드 카드는 데이터베이스의 `backend`에 자체 문자열 대체 메커니즘을 사용하도록 지시합니다. 이는 (hopefully잘하면) 안전할 것입니다.

안타깝게도 데이터베이스 `backend` 간의 와일드카드에 일관되지 않은 점이 있습니다.
대부분 모듈에서 `?` 또는 `%s`를 사용하지만 다른 모듈은 `:0` 또는 `:1`과 같은 다른 기호를 사용하여 매개변수를 참조할 수 있습니다. 즉, 사용 중인 데이터베이스 모듈의 문서를 참고해야 할 것입니다.
데이터베이스 모듈의 `paramstyle` 속성에는 인용 스타일에 대한 정보도 포함되어 있습니다.

다른 데이터베이스 테이블이나 테이블 내부에서 데이터를 단순히 가져오는 경우, 보통 데이터베이스 `API`를 사용하면 충분합니다. 좀 더 복잡한 작업을 하려면 객체-관계 `mapper`에서 제공되는 것과 같은 고급 인터페이스를 사용하는 것이 좋습니다.
[SQLAlchemy](//www.sqlalchemy.org/)와 같은 라이브러리는 Python 클래스로써 데이터베이스 테이블을 설명할 수 있도록 허용하고 데이터베이스 작업이 대부분 기본적인 `SQL` 대부분을 숨기는 동안 데이터베이스 연산을 수행될 수 있도록 합니다.

## 6.9. Decoding and Encoding Hexadecimal Digits

#### Problem

16진수의 문자열을 바이트 문자열로 디코딩하거나 16진수로 바이트 문자열을 인코딩 해야 합니다.

#### Solution

16진수의 `raw` 문자열을 간단하게 인코딩 또는 디코딩하려면 `binascii` 모듈을 사용합니다.

```python
>>> # Initial byte string
>>> s = b'hello'
>>> import binascii
>>> h = binascii.b2a_hex(s)
>>> h
b'68656c6c6f'
>>> # Decode back to bytes
>>> binascii.a2b_hex(h)
b'hello'
```

비슷한 기능으로 `base64` 모듈을 찾을 수 있습니다.

```python
>>> import base64
>>> h = base64.b16encode(s)
>>> h
b'68656C6C6F'
>>> base64.b16decode(h)
b'hello'
```

#### Discussion

대부분의 경우 16진수로의 변환은 표시된 함수를 이용하면 간단합니다.
두 기술의 주된 차이점은 `case folding`입니다. `base64.b16decode()`와 `base64.b16encode()` 함수는 대문자 16진수 문자로만 작동하지만 `binascii` 함수는 어떤 케이스라도 동작합니다.

인코딩 함수에 의해 생성된 출력은 항상 바이트 문자열이라는 점도 중요합니다. 출력을 위해 유니코드로 강제 변환하려면 추가 디코딩 단계를 추가해야 할 수도 있습니다.

```python
>>> h = base64.b16encode(s)
>>> print(h)
b'68656C6C6F'
>>> print(h_decode('ascii'))
68656C6C6F
```

16진수를 디코딩 할 때 `b16decode()`와 `a2b_hex()` 함수는 바이트 또는 유니코드 문자열을 받습니다. 하지만 이 문자열은 반드시 ASCII 인코딩된 16진수만 포함해야 합니다.

## 6.10. Decoding and Encoding Base64

#### Problem

바이너리 데이터를 `Base64` 인코딩을 사용하여 인코딩 또는 디코딩 해야 합니다.

#### Solution

`base64` 모듈은 원하는 것을 정확하게 수행하는 두 함수 `b64encode()` 와 `b64decode()`가 있습니다.

```python
>>> # Some byte data
>>> s = b'hello'
>>> import base64
>>> # Encode as Base64
>>> a = base64.b64encode(s)
>>> a
b'aGVsbGB='
>>> # Decode from Base64
>>> base64.b64decode(a)
b'hello'
```

#### Discussion

`Base64` 인코딩은 바이트 문자열 및 바이트 배열과 같은 `byte-oriented` 데이터에만 사용하기 위한 것입니다. 더군다나 인코딩 과정의 출력도 항상 바이트 문자열입니다. 유니코드 텍스트와 함께 `Byte64` 인코딩 된 데이터를 섞으려면 추가적인 디코딩 단계를 수행해야 할 수도 있습니다.

```python
>>> a = base64.b64encode(s).decode('ascii')
>>> a
'aGVsbGB='
```

`Base64` 디코딩할 때 바이트 문자열과 유니코드 텍스트 문자열 둘 다 지원될 수 있습니다. 하지만 유니코드 문자는 `ASCII` 문자만 포함할 수 있습니다.
