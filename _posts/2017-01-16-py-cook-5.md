---
layout: post
title: Python cookbook Chapter 5 한글
tags: ['python', 'docs', 'os', 'file', 'data', '한글']
progress: 76
---

<div id='index-table'>
<h2>5. Files and I/O</h2>
</div>

- - -


<div class='warn'>
이 문서는 Python Coobook 3rd edition - O'REILLY, David Beazley & Brian K. jones 를 참고한 것이며 개인적인 번역으로 인한 오역이 있을 수 있습니다.<br> <a href="//wikidocs.net/book/1">Python을 완전히 처음 접하는 경우</a>에는 적합하지 않습니다.<br>
</div>

모든 프로그램은 `input`과 `output`을 수행합니다. 이 챕터는 다른 종류의 파일과 텍스트와 바이너리 파일을 포함하는 것과 함께 동작하기 위한 일반적인 `idiom(관용적인 표현)`을 다룹니다. 파일 이름이나 디렉터리를 조작하는 기술 또한 다루게 됩니다.

## 5.1. Reading and Writing Text Data

#### Problem

텍스트 데이터를 읽고 써야 하고 `ASCII`, `UTF-8` 또는 `UTF-16`과 같은 다른 텍스트의 인코딩을 가능하게 해야 합니다.

#### Solution

텍스트 파일을 읽기 위해 `open()` 함수를 `rt`모드와 함께 사용합니다.

```python
# Read the entire file as a single string
with open('somefile.txt', 'rt') as f:
    data = f.read()

# Iterate over the lines of the file
with open('somefile.txt', 'rt') as f:
    for line in f:
        # process line
        ...
```

비슷하게, 텍스트 파일에 쓰기 위해 `wt` 모드와 함께 `open()`을 사용하고 이전 내용(있다면)을 지우고 덮어씁니다.

```python
# Write chunks of text data
with open('somefile.txt', 'wt') as f:
    f.write(text1)
    f.write(text2)
    ...

# Redirected print statement
with open('somefile.txt', 'wt') as f:
    print(line1, file=f)
    print(line2, file=f)
    ...
```

파일의 끝에 추가하기 위해 `at` 모드와 함께 `open()`을 사용합니다.

기본적으로 파일은 `sys.getdefaultencoding()`에서 찾아 볼 수 있는 기본적인 텍스트 인코딩 시스템을 사용하여 읽고 쓰여집니다. 대부분 머신에서 `utf-8`로 되어 있습니다. 만일 텍스트가 다른 인코딩으로 읽거나 쓰이는 것을 알고 있다면 선택적으로 `open()`을 위한 인코딩 파라미터를 제공합니다.

```python
with open('somefile.txt', 'rt', encoding='latin-1') as f:
    ...
```

Python은 수백개의 가능한 텍스트 인코딩을 이해합니다. 하지만 좀 더 일반적인 인코딩은 `ascii`, `latin-1`, `utf-8`과 `utf-16`입니다. `UTF-8`은 보통 웹 애플리케이션에서 동작하는 경우에 안전합니다. `ascii`는 `U+0000`과 `U+007E` 범위의 7비트 문자에 대응됩니다. `latin-1`은 `U+0000`에서 `U+00FE` 유니코드 문자를 위한 0-255 바이트에 직접 매핑됩니다. `latin-1` 인코딩은 알려지지 않은 인코딩의 텍스트를 읽을 때 절대 디코딩 에러를 생성하지 않는 점이 주목할 만합니다. `latin-1`로 파일을 읽는 것은 완벽하게 정확한 텍스트 디코딩을 생성하지는 못할 수 있지만 유용한 데이터를 밖으로 충분히 추출할 수는 있습니다. 또한 나중에 데이터를 다시 쓸 때 원본 입력 데이터가 보존될 것입니다.

#### Discussion

텍스트 파일을 읽고 쓰는 것은 전형적으로 매우 단순합니다. 하지만 명심해야 할 많은 미묘한 점이 있습니다. 첫 번째로 예제에 사용된 `with` 문은 파일이 사용될 `context(작업)`가 설정됩니다. **컨트롤이 `with` 블록을 넘어서면 파일은 자동적으로 닫힙니다.** 꼭 `with` 문을 사용할 필요는 없지만 사용하지 않는다면, 파일을 닫는 것을 꼭 기억해야 합니다.

```python
f = open('somefile.txt', 'rt')
data = f.read()
f.close()
```

또 다른 사소한 문제는 윈도우와 유닉스의 서로 다른 개행의 인식(즉, `\n` vs `\r\n`)을 고려하는 것입니다. 기본적으로, Python은 `universal newline` 모드로 알려져 있습니다. 이 모드에서 모든 일반적인 개행 규칙이 인식되고, 개행 문자는 읽기가 진행되는 동안 단일 `\n`문자로 변환됩니다. 비슷하게, `\n` 개행 문자는 시스템 기본 개행 문자로 변환되어 출력됩니다. 만약 이런 번역을 원하지 않는다면 제공되는 `newline=''` 인수를 `open()`에 다음과 같이 사용합니다.

```python
# Read with disabled new line translation
with open('somefile.txt', 'rt', newline='') as f:
    ...
```

이 차이를 설명하기 위해 다음 윈도우로 인코딩 된 `hello world!\r\n`의 `raw data`가 포함된 텍스트 파일의 내용을 읽는 유닉스 머신에 대한 예가 있습니다.

```python
# newline translation enabled(the default)
f = open('hello.txt', 'rt')
print(f.read())
# hello world!\n

# newline translation disabled
g = open('hello.txt', 'rt', newline='')
print(g.read())
# hello world!\r\n
```

마지막으로 고려되는 텍스트 파일의 인코딩 문제가 있습니다. 텍스트 파일을 읽고 쓸때 인코딩 또는 디코딩 에러에 직면하게 됩니다.

```python
>>> f = open('sample.txt', 'rt', encoding='ascii')
>>> f.read()
# "UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position"
```

이 에러를 얻는다면 보통 정확한 인코딩으로 파일을 읽을 수 없다는 것을 의미합니다. 읽고 있는 어떤 내용이든 신중하게 읽고 올바르게 해야 합니다.(예를 들어 `Latin-1` 대신`UTF-8`로 읽는 데이터나 필요하게 되는 무엇이든) 여전히 인코딩 에러 발생 가능성이 있다면 에러를 다루기 위해 선택적인 `error` 인수를 `open()`에 제공합니다. 다음은 일반적인 에러를 핸들링하는 예입니다.

```python
# Replace bad chars with nicode U+fffd replacement char
f = open('sample.txt', 'rt', encoding='ascii', error='replace')
print(f.read())     # 'Spicy Jalape?o!'
# Ignore badchars entirely
g = open('sample.txt', 'rt', encoding='ascii', errors='ignore')
print(g.read())     # 'Spicy Jalapeo!'
```

끊임없이 `open()`에 대한 인코딩과 에러 인수를 노리고 해킹을 많이 한다면 곤란해질 것입니다. 텍스트에 대한 첫 번째 규칙은 항상 적절한 텍스트 인코딩을 사용하는 지 확인하기만 하면 되는 것입니다. 의심스러우면 기본 설정을 사용하시면 됩니다.(전형적인 `UTF-8`)

## 5.2. Printing to a File

#### Problem

`print()` 함수의 출력을 파일로 `redirect`하려고 합니다.

#### Solution

다음과 같이 `file` 키워드를 `print()`의 인수로 사용합니다.

```python
with open('somefile.txt', 'rt') as f:
    print('Hello World!', file=f)
```

#### Discussion

이 외에 파일에 `print`하는 것은 그리 많지 않습니다. 하지만 파일이 텍스트 모드로 열려있는지 확인해야 합니다. 파일이 바이너리 모드라면 `print`가 실패할 것입니다.

## 5.3. Printing with a Different Separator or Line Ending

#### Problem

`print()`를 사용하여 데이터를 출력하고 싶지만, `separator(구분자)` 또는 라인 끝을 바꾸길 원합니다.

#### Solution

출력을 원하는 대로 변경하기 위해 `sep` 과 `end` 키워드 인수를 `print()`에 사용합니다.

```python
>>> print('ACME', 50, 91.5)
ACME 50 91.5
>>> print('ACME', 50, 91.5, sep=',')
ACME,50,91.5
>>> print('ACME', 50, 91.5, sep=',', end='!!\n')
ACME,50,91.5!!

```

`end` 인수를 사용하는 것은 또한 출력에서 개행의 출력을 막는 방법입니다. 예를 들면

```python
>>> for i in range(5):
...     print(i)
...
0
1
2
3
4
>>> for i in range(5):
...     print(i, end=' ')
...
0 1 2 3 4 >>>
```

#### Discussion

`print()`를 다른 구분자 항목과 함께 사용하는 것은 항목에 스페이스 구분자를 하는 보다 나은 것이 필요할 때 종종 데이터를 출력하기 위한 가장 쉬운 방법이 됩니다. 때로는 프로그래머들이 동일한 목적을 위해 `str.join()`을 사용하는 것도 볼 수 있습니다.

```python
>>> print(','.join('ACME', '50', '91.5'))
ACME,50,91.5
```

`str.join()`을 사용하는 문제점은 오직 문자열에만 동작하는 것입니다. 이는 동작을 위한 다양한 기교를 수행하기 위해 종종 필요하다는 것을 의미합니다.

```python
>>> row = ('ACME', 50, 91.5)
>>> print(','.join(row))
TypeError: sequence item 1: expected str instance, int found
>>> print(','.join(str(x) for x in row))
ACME, 50, 91.5
```

대신 다음과 같이 쓸 수 있습니다.

```python
>>> print(*row, sep=',')
ACME,50,91.5
```

## 5.4. Reading and Writing Binary Data

#### Problem

이미지, 사운드 파일 등에서 발견된 바이너리 데이터를 읽고 써야합니다.

#### Solution

바이너리 데이터를 읽거나 쓰기 위해 모드 `rb` 또는 `wb`로 `open()`을 사용합니다.

```python
# Read the entire file as a single byte string
with open('somefile.bin', 'rb') as f:
    data = f.read()

# Write binary data to a file
with open('somefile.bin', 'wb') as f:
    f.write(b'Hello World')
```

바이너리를 읽을 때는 반환된 모든 데이터가 텍스트 문자열이 아닌 바이트 문자열의 형태가 된다는 것을 강조하는 것이 중요합니다. 마찬가지로 쓸 때는 바이트 데이터를 노출하는 객체 형태의 데이터를 제공해야 합니다.(예. 바이트 문자열, `bytearray` 객체 등)

#### Discussion

바이너리 데이터를 읽을 때는 바이트 문자열과 텍스트 문자열이 취하는 미묘한 의미 차이가 있습니다. 특히 `indexing`과 바이트 문자열 대신 및 정수 바이트 값으로 반환되는 `iteration`에 유의하셔야 합니다.

```python
t = b'Hello World'
for c in t:
    print(c)
# 72 101 108 108 111 ...
```

바이너리 모드 파일에서 텍스트를 읽거나 써야할 때는 인코딩이나 디코딩을 생각하셔야 합니다.

```python
with open('somefile.bin', 'rb') as f:
    data = f.read(16)
    text = data.decode('utf-8')

with open('somefile.bin', 'wb') as f:
    text = 'Hello World'
    f.write(text.encode('utf-8'))
```

바이너리 I/O의 덜 알려진 점은 배열과 C 구조같은 객체가 `bytes` 객체로 즉시 변환하는 과정 없이 쓰는데 사용될 수 있다는 것입니다.

```python
import array
nums = array.array('i', [1, 2, 3, 4])
with open('data.bin', 'wb') as f:
    f.write(nums)
```

이것은 직접 작업이 가능할 수 있는 연산을 위해 메모리 버퍼에 노출되는 `buffer interface` 라고 불리는 구현하는 모든 객체에 적용됩니다.
바이너리 데이터를 쓰는 것은 연산의 한가지입니다.

많은 객체들이 또한 파일의 `readinto()` 메서드를 사용하여 바이너리 데이터가 기본 메모리로 직접 읽을 수 있도록 허용합니다.

```python
import array
array.array('i', [0,0,0,0,0,0,0,0])
with open('data.bin', 'rb') as f:
    f.readinto(a)
```

하지만 이 테크닉을 사용할 때 지정한 플랫폼과 워드 크기 및 바이트 순서같은 것에 의존할 수 있으므로 주의해야 합니다.(빅 엔디안 vs 리틀 엔디안)
[5.9장](#reading-binary-data-into-a-mutable-buffer)에 바이너리 데이터를 가변 버퍼에 읽는 다른 예제가 있습니다.

## 5.5. Writing to a File That Doesn't Already Exist

#### Problem

파일에 데이터를 쓰길 원하지만 그 파일이 파일 시스템에 없을 때만 쓰려고 합니다.

#### Solution

이 문제는 일반적인 `w` 모드 대신 덜 알려진 `x` 모드를 `open()`에 사용함으로써 쉽게 해결됩니다.

```python
>>> with open('somefile', 'wt') as f:
...     f.write('Hello\n')
...
>>> with open('somefile', 'xt') as f:
...     f.wrtie('Hello\n')
FileExistsError: File exists: 'somefile'
```

#### Discussion

이 장은 때때로 파일을 쓸 때(즉, 실수로 존재하는 파일을 덮어 쓰는 것) 일어나는 문제를 위한 매우 우아한 해결책을 제시합니다. 대안은 다음과 같이 파일에 먼저 테스트를 하는 것입니다.

```python
import os
if not os.path.exists('somefile'):
    with open('somefile', 'wt') as f:
        f.write('Hello\n')
else:
    print('File already exists!')
```

명백히 `x` 파일 모드를 사용하는 것은 훨씬 복잡하지 않습니다. `x` 모드가 `open()` 함수를 위한 Python 3 특정 확장이라는 것을 아는 것이 중요합니다. 특히 이전 Python 버전이나 C 라이브러리가 사용된 Python의 구현에는 이런 모드가 존재하지 않습니다.

## 5.6. Performing I/O Operations on a string

#### Problem

텍스트 또는 바이너리 문자열을 대신 파일 같은 객체에 동작하기 위해 작성된 코드에 넘겨주려고 합니다.

#### Solution

문자열 데이터에 동작하는 파일 같은 객체를 만들기 위해 `io.StringIO()`와 `io.BytesIO()` 클래스를 사용합니다.

```python
>>> s = io.StringIO()
>>> s.write('Hello World\n')
12
>>> print('This is a test', file=s)
15
>>> # Get all of the data written so far
>>> s.getvalue()
'Hello World\nThis is a test\n'
>>> # Wrap a file interface around an existing string
>>> s = io.StringIO('Hello\nWorld\n')
>>> s.read(4)
'Hell'
>>> s.read()
'o\nWorld\n'
```

`io.StringIO` 클래스는 텍스트를 위해서만 사용되어야 합니다. 바이너리 데이터에 동작하려면 `io.BytesIO` 클래스를 대신 사용합니다.

```python
>>> s = io.BytesIO()
>>> s.write(b'binary data')
>>> s.getvalue()
b'binary data'
```

#### Discussion

`StringIO`와 `BytesIO` 일반적인 파일을 어떤 이유로 모방해야 하는 시나리오에 가장 유용합니다. 예를 들어 단위 테스트에서 일반 파일과 함께 동작하는 다른 함수에 넘긴 테스트 데이터를 포함하는 파일 같은 객체를 만들기 위해 `StringIO`를 사용할 수 있습니다.

`StringIO`와 `BytesIO` 인스턴스가 적절한 정수 **`file descriptor`를 가지고 있지 않다는** 점에 유의하시기 바랍니다. 그러므로 실시간 레벨의 파일, 파이프, 소켓과 같은 파일에 사용이 필요한 코드에는 동작하지 않습니다.

## 5.7. Reading and Writing Compressed Datafiles

#### Problem

`gzip` 또는 `bz2` 압축 파일에서 데이터를 읽고 써야합니다.

#### Solution

`gzip`과 `bz2` 모듈은 이러한 파일을 쉽게 사용하게 해줍니다. 두 모듈은 이 목적에 사용할 수 있는 `open()` 구현의 대안을 제공합니다. 예를 들어 텍스트로 압축된 파일을 읽기 위해 다음을 수행합니다.

```python
# gzip compression
import gzip
with gzip.open('somefile.gz', 'rt') as f:
    text = f.read()

# bz2 compression
import bz2
with bz2.open('somefile.bz2', 'rt') as f:
    text = f.read()
```

비슷하게 압축된 파일을 쓰기 위해 다음을 수행합니다.

```python
# gzip compression
import gzip
with gzip.open('somefile.gz', 'wt') as f:
    f.write(text)

# bz2 compression
import bz2
with bz2.open('somefile.bz2', 'wt') as f:
    f.write(text)
```

위와 같이 모든 I/O가 텍스트에 사용되고 유니코드 인코딩/디코딩을 수행합니다. 바이너리 데이터로 대신 동작하려 한다면 `rb` 또는 `wb` 모드를 사용하시기 바랍니다.

#### Discussion

대부분을 위해 압축된 데이터에 읽거나 쓰는 것은 복잡하지는 않습니다. 하지만 정확한 파일 모드를 고르는 것이 매우 중요하다는 것에 유의하시기 바랍니다. 특정한 모드가 없다면 기본적인 모드는 바이너리이며, 텍스트를 받는 것으로 예상되는 프로그램은 중단됩니다.
`gzip.open()`과 `bz2.open()` 모두 `encoding`, `errors`, `newline` 등을 포함하는  `built-in open()` 함수와 동일한 파라미터를 받습니다.

압축된 데이터를 작성할 때는 압축 레벨이 `compressedlevel` 키워드 인수를 사용하여 선택적으로 지정될 수 있습니다.

```python
with gzip.open('somefile.gz', 'wt', compresslevel=5) as f:
    f.write(text)
```

기본 레벨은 9이며 가장 높은 압축 레벨이 제공됩니다. 낱은 레벨이 좀 더 나은 성능을 제공하지만 압축은 그만큼 많이 되지 않습니다.

마지막으로 거의 알려지지 않은 `gzip.open()` 과 `bz2.open()`의 기능은 바이너리 모드로 열린 파일 위에 존재하는 레이어가 될 수 있다는 것입니다.

```python
import gzip
f = open('somefile.gz', 'rb')
with gzip.open(f, 'rt') as g:
    text = g.read()
```

이는 소켓, 파이프, 인메모리 파일 같은 다양한 파일 같은 객체와 함께 작동하는 `gzip`과 `bz2` 모듈을 허용합니다.

## 5.8. Iterating Over Fixed-Sized Records

#### Problem

파일을 라인으로써 `iterating` 하는 대신에 고정 길이의 레코드 또는 `chunk`의 `collection`으로 `iterate` 하길 원합니다.

#### Solution

멋진 트릭인 `iter()` 함수와 `functools.partial()`을 사용합니다.

```python
from functools import partial

RECORD_SIZE = 32

with open('somefile.data', 'rb') as f:
    records = iter(partial(f.read, RECORE_SIZE), b'')
    for r in records:
        ...
```

이 예제의 `records` 객체는 고정 길이의 `chunk`를 파일에 끝에 도달할 때까지 생성하게 되는 `iterable` 객체입니다. 하지만 파일의 길이가 레코드 길이 마지막 항목은 파일의 크기가 레코드 크기의 정확한 배수가 되지 않는 경우 예상 보다 적은 바이트를 가진다는 것에 유의하셔야 합니다.

#### Discussion

`iter()` 함수의 거의 알려지지 않은 기능은 `callable` 객체와 `sentinel` 값을 전달할 경우에 `iterator`를 만들 수 있다는 것입니다. `iterator`의 결과는 단순히 제공된 `callable` 객체를 `sentinel`을 반환할 때 까지 계속해서 호출하는 것이며 그 지점에서 `iteration`이 정지됩니다.

이 Solution에서, `functools.partial`이 각 시간에서 호출되는 파일에서 고정 갯수의 바이트를 읽는 `callable` 객체를 만들기 위해 사용됩니다. `b''`의 `sentinel`은 파일을 읽을 때 반환되지만 파일의 끝에 도달할 때도 반환됩니다.

마지막으로 Solution은 파일이 바이너리 모드로 열리게 되는 것을 보여줍니다. 고정 길이 레코드를 읽는 경우에 이는 가장 일반적인 경우가 될 수 있습니다. 텍스트 파일의 경우 줄 단위(기본 `iteration` 동작)로 읽는 것이 좀 더 일반적입니다.

## 5.9. Reading Binary Data into a Mutable Buffer

#### Problem

바이너리 데이터를 직접 가변 버퍼로 어떠한 중간 복사 과정 없이 읽으려고 합니다. 아마 데이터를 현재 위치에서 변형하고 파일에 다시 쓰기를 원할 것입니다.

#### Solution

가변 배열의 데이터를 읽기 위해서는 파일의 `readinto()`메서드를 사용합니다.

```python
import os.path

def read_into_buffer(filename):
    buf = bytearray(os.path.getsize(filename))
    with open(filename, 'rb') as f:
        f.readinto(buf)
    return buf
```

다음은 사용 예제입니다.

```python
>>> # Write a sample file
>>> with open('sample.bin', 'wb') as f:
...     f.write(b'Hello World')
...
>>> buf = read_into_buffer('sample.bin')
>>> buf
bytearray(b'Hello World')
>>> buf[0:5] = b'Hallo'
>>> buf
bytearray(b'Hallo World')
>>> with open('newsample.bin', 'wb') as f:
...    f.write(buf)
...
11
```

#### Discussion

파일의 `readinto()` 메서드는 데이터와 함께 미리 할당된 아무 배열이나 채우기 위해 사용될 수 있습니다. 이는 심지어 `array` 모듈 또는 `numpy` 같은 라이브러리에서 생성된 배열을 포함합니다. 일반적인 `read()` 메서드와는 다르게 `readinto()`는 새 객체에 할당하고 반환하는 것 보다는 존재하는 버퍼의 내용을 채우게 됩니다. 그러므로 추가적인 메모리 할당을 방지하기 위해 이를 사용할 수 있게 됩니다. 예를 들어 동일한 길이의 레코드로 구성된 바이너리 파일을 읽을 경우 다음과 같이 작성 할 수 있습니다.

```python
# Size of each record (adjust value)
record_size = 32

buf = bytearray(record_size)
with open('somefile', 'rb') as f:
    while True:
        n = f.readinto(buf)
        if n < record_size:
            break
        # Use the contents of buf
        ...
```

여기에 사용하기 위한 또 다른 흥미로운 기능은 기존 버퍼의 `zero-copy slice`를 만들고 내용을 변경하는 `memoryview`가 된다는 것입니다.

```python
>>> buf
bytearray(b'Hello World')
>>> m1 = memoryview(buf)
>>> m2 = m1[-5:]
>>> m2
<memory at 0x100681390>
>>> m2[:] = b'WORLD'
>>> buf
bytearray(b'Hello WORLD')
```

`f.readino()`의 한가지 주의할 점은 항상 리턴 코드를 체크해야 한다는 것입니다. 이는 실제로 읽는 바이트의 수입니다.

만일 바이트의 수가 제공된 버퍼의 크기보다 작은 경우 `truncate` 되거나 손상된 데이터일 수 있습니다.(예. 정확한 바이트의 수 읽기를 예상한 경우)

마지막으로 다양한 라이브러리 모듈에서 다른 `into` 관련된 함수를 조심하시기 바랍니다.(`recv_into()`, `pack_into()` 등) 많은 Python의 부분에서 직접 I/O 또는 배열과 버퍼의 내용을 채우거나 변경하기 위해 사용되는 데이터 접근을 지원합니다.

[6.12장]()에 바이너리 구조 해석과 `memoryview` 사용에 대한 중요한 심화 예제를 참고하시기 바랍니다.

## 5.10. Memory Mapping Binary Files

#### Problem

바이너리 파일에서 가변 바이트 배열로 메모리 매핑하여 내용에 랜덤 액세스가 가능하거나 내부 수정이 가능하기를 원합니다.

#### Solution

메모리를 파일에 매핑하기 위해 `mmap` 모듈을 사용합니다. 다음은 파일을 열고 매모리 맵을 간편한 방식으로 하는 방법을 보여주는 유틸리티 함수입니다.

```python
import os
import mmap

def memory_map(filename, access=mmap.ACCESS_WRITE):
    size = os.path.getsize(filename)
    fd = os.open(filename, os.O_RDWR)
    return mmap.mmap(fd, size, access=access)
```

이 함수를 사용하기 위해 이미 생성되고 데이터가 채워진 파일이 있어야 합니다. 다음은 파일을 만들고 원하는 크기로 확장하는 방법의 예제입니다.

```python
size = 1000000
with open('data', 'wb') as f:
    f.seek(size-1)
    f.write(b'\x00')
```

이제 `memory_map()` 함수를 사용하여 메모리에 내용을 매핑합니다.

```python
>>> m = memory_map('data')
>>> len(m)
1000000
>>> m[0:10]
b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
>>> m[0]
0
>>> # Reassign a slice
>>> m[0:11] = b'Hello World'
>>> m.close()
>>> # verity that changes were made
>>> with open('data', 'rb') as f:
...     print(f.read(11))
...
b'Hello World'
```

`mmap()`에 의해 반환된 `mmap` 객체는 또한 `context manager`로써 사용될 수 있습니다. 이는 기본 파일이 자동적으로 닫히는 경우입니다.

```python
>>> with memory_map('data') as m:
...     print(len(m))
...     print(m[0:10])
...
1000000
b'Hello World'
>>> m.closed
True
```

기본적으로 위의 `memory_map()` 함수는 읽고 쓰기 위해 파일을 엽니다.
데이터의 수정 사항은 원본 파일에 다시 복사됩니다. 만일 읽기 전용 파일에 대신 액세스 해야 한다면 인수에 액세스 하기 위해 `mmap.ACCESS_READ`를 제공합니다.

```python
m = memory_map(filename, mmap.ACCESS_READ)
```

데이터를 지역적으로 변경하고자 하지만 원본 파일에 다시 변경하여 쓰고 싶지는 않은 경우 `mmap.ACCESS_COPY`를 사용합니다.

```python
m = memory_map(filename, mmap.ACCESS_COPY)
```

#### Discussion

파일을 메모리에 매핑하기 위해 `mmap`을 사용하는 것은 무작위로 파일의 내용에 액세스하는 데 효율적이고 우아한 방법이 될 수 있습니다. 예를 들어 파일을 열고 `seek()`, `read()`와 `write()`를 호출을 다양하게 조합하여 수행하여 파일을 여는 것 대신 파일을 간단히 매핑하고 `slicing` 연산을 사용하여 데이터에 액세스 할 수 있습니다.

일반적으로, 메모리는 `bytearray` 객체로 보이는 `mmap()`에 의해 노출됩니다. 하지만 `memoryview`를 사용하여 데이터를 다르게 해석할 수 있습니다.

```python
>>> m = memory_map('data')
>>> # Memoryview of unsigned integers
>>> v = memoryview(m).cast('I')
>>> v[0] = 7
>>> m[0:4]
b'\x07\x00\x00\x00'
>>> m[0:4] = b'\x07\x01\x00\x00'
>>> v[0]
263
```

메모리를 파일에 매핑한다고 해서 전체 파일이 메모리에 읽히지는 않는다는 것을 강조해야 합니다. 즉 메모리 버퍼나 배열 종류로 복제되지는 않습니다.
대신 운영체제가 가상 파일 내용을 위한 메모리의 영역만을 예약합니다.
다른 영역에 접근함으로써 파일의 해당 부분은 읽고 필요한 메모리 영역에 매핑됩니다.
하지만 액세스가 전혀 일어나지 않는 파일의 일부는 단순히 디스크에 남아있습니다. 이는 모든 곳에서 투명하게 발생합니다.

하나 이상의 Python 인터프리터 메모리가 동일한 파일을 매핑할 경우 `mmap` 객체의 결과는 인터프리터 사이에서 데이터를 교환하는 데 사용될 수 있습니다. 즉 모든 인터프리터가 데이터를 동시에 읽기/쓰기 할 수 있고 한 인터프리터에서 변경된 데이터는 자동적으로 다른 곳에 나타날 것입니다. 분명히 동기화하는 것에 약간의 주의가 필요하지만 이런 종류의 접근은 때로는 파이프나 소켓을 통한 메시지에서 데이터를 전달하는 대안으로 사용될 수도 있습니다.

위에서 보인 것과 같이 이 장은 유닉스와 윈도우 모두 동작 가능한 일반적인 목적으로 작성된 것입니다. 숨은 `mmap()` 호출의 사용을 고려하여 플랫폼의 차이가 있다는 것에 유의하시기 바랍니다.
추가로 익명의 매핑된 메모리 영역을 생성하기 위한 옵션이 있습니다.
이에 흥미가 있다면 [이 주제](//docs.python.org/3/library/mmap.html)에 대한 Python 문서를 주의 깊게 읽어 보시기 바랍니다.

## 5.11. Manipulating Pathnames

#### Problem

기본 파일 이름, 디렉터리 이름, 절대 경로 등을 찾기 위해 경로 이름을 변경해야 합니다.

#### Solution

경로 이름을 변경하기 위해서는 `os.path` 모듈의 함수를 사용합니다. 다음은 중요한 기능을 소개하는 대화형 예제 입니다.

```python
>>> import os
>>> path = '/Users/beazley/Data/data.csv'
>>> # Get the last component of the path
>>> os.path.basename(path)
'data.csv'
>>> # Get the directory name
>>> os.path.dirname(path)
'/Users/beazley/Data'
>>> # Join path components together
>>> os.path.join('tmp', 'data', os.path.basename(path))
'tmp/data/data.csv'
>>> # Expand the user's home directory
>>> path = '~/Data/data.csv'
>>> os.path.expanduser(path)
'/Users/beazley/Data/data.csv'
>>> # Split the file extension
>>> os.path.splitext(path)
('~/Data/data', '.csv')
```

#### Discussion

어떤 파일 이름을 변경하려면 표준 문자열 연산을 사용한 코드로 시도하는 대신에 `os.path` 모듈을 사용해야 합니다.
부분적으로 이는 이식성(potability)을 위한 것입니다.
`os.path` 모듈은 유닉스와 윈도우 사이의 차이에 대해 알고 있고 `Data/data.csv`와 `Data\data.csv` 같이 안정적으로 파일 이름을 다룰 수 있습니다.
두 번째로 이런 과정을 다시 만드는데 시간을 쓰지 않아도 됩니다. 이미 제공된 기능을 사용하는 것이 일반적으로 가장 좋습니다.

`os.path` 모듈은 이 장에 소개되지 않은 더 많은 기능이 있습니다. 테스팅, 심볼릭 링크 등과 관련된 더 많은 함수는 문서를 참고하시기 바랍니다.

## 5.12. Testing for the Existence of a File

#### Problem

파일 또는 디렉터리가 존재하는지 테스트를 해야 합니다.

#### Solution

파일 또는 디렉터리의 존재성을 테스트 하기 위해 `os.path` 모듈을 사용합니다.

```python
>>> import os
>>> os.path.exists('/etc/passwd')
True
>>> os.path.exists('/tmp/spam')
False
```

어떤 종류의 파일인지 보기 위해 추가적인 테스트를 수행할 수도 있습니다.
이런 테스트는 파일이 존재하지 않을 경우에 `False`를 반환합니다.

```python
>>> # Is a regular file
>>> os.path.isfile('/etc/passwd')
True
>>> # Is a directory
>>> os.path.isdir('/etc/passwd')
False
>>> # Is a symbolic link
>>> os.path.islink('/usr/local/bin/python3')
True
>>> # Get the file linked to
>>> os.path.realpath('usr/local/bin/python3')
'/usr/local/bin/python3.3'
```

메타데이터(파일 크기나 최근 변경 일)를 얻어야 한다면 이 또한 `os.path` 모듈에서 가능합니다.

```python
>>> os.path.getsize('/etc/passwd')
3669
>>> os.path.getmtime('/etc/passwd')
1272478234.0
>>> import time
>>> time.ctime(os.path.getmtime('/etc/passwd'))
'Wed Apr 28 13:10:34 2010'
```

#### Discussion

파일 테스팅은 `os.path`를 사용한 단순한 작업입니다. 아마 스크립트를 작성할 때 주의할 점은 특히 메타데이터를 얻는 작업을 위한 사용 권한에 대해 걱정할 필요가 있다는 것입니다.

```python
>>> os.path.getsize('/Users/guido/Desktop/foo.txt')
PermissionError: Permission denied
```

## 5.13. Getting a Directory Listing

#### Problem

파일 시스템의 디렉터리에 포함된 파일의 목록을 얻길 원합니다.

#### Solution

디렉터리에서 파일의 목록을 얻기 위해서는 `os.listdir()` 함수를 사용합니다.

```python
import os
names = os.listdir('somedir')
```

이는 `raw` 모든 파일, 서브 디렉터리, 심볼릭 링크 등을 포함한 디렉터리 목록을 줄 것입니다. 데이터를 어떤 방법으로 필터링 해야 한다면 `os.path` 라이브러리에서 다양한 함수와 결합된 `list comprehension`을 사용하는 것을 고려하시기 바랍니다.

```python
import os.path
# Get all regular files
names = [name for name in os.listdir('somedir') if os.path.isfile(os.path.join('somedir', name))]

# Get all dirs
dirnames = [name for name in os.listdir('somedir') if os.path.isdir(os.path.join('somedir', name))]
```

문자열의 `startswith()`와 `endswith()` 메서드 역시 디렉터리의 내용을 필터링하는데 유용할 수 있습니다.

```python
pyfiles = [name for name in os.listdir('somedir') if name.endswith('.py')]
```

파일 이름을 매칭하기 위해 `glob` 또는 `fnmatch` 모듈을 대신 사용할 수도 있습니다.

```python
import glob
pyfiles = glob.glob('somedir/*.py')

from fnmatch import fnmatch
pyfiles = [name for name in os.listdir('somedir') if fnmatch(name, '*.py')]
```

#### Discussion

디렉터리의 리스트를 얻는 것은 쉽지만 디렉터리에서 항목 이름만 주어집니다. 파일 크기, 최근 변경일 등의 추가적인 메타데이터를 얻으려면 `os.path` 모듈에서 추가적인 함수를 사용하거나 `os.stat()` 함수를 사용할 필요가 있습니다.

```python
# Example of getting a directory Listing
import os
import os.path
import glob

pyfiles = glob.glob('*.py')

# Get file sizes and modification dates
name_sz_date = [(name, os.path.getsize(name), os.path.getmtime(name)) for name in pyfiles]

for name, size, mtime in name_sz_date:
    print(name, size, mtime)

# Alternative: Get file metadata
file_metadata = [(name, os.stat(name)) for name in pyfiles]
for name, meta in file_metadata:
    print(name, meta.st_size, meta.st_mtime)
```

마지막으로, 인코딩에 관련된 파일 이름 핸들링에서 일어날 수 있는 미묘한 문제에 주의하시기 바랍니다. 일반적으로 `os.listdir()`와 같은 함수에 의해 반환된 항목은 기본 파일 인코딩 시스템에 따라 디코딩됩니다. 하지만 특정 상황에서 디코딩 불가능한 파일 이름이 발견될 가능성도 있습니다.
[5.14장](#bypassing-filename-encoding)과 [5.15장](#printing-bad-filenames)에 이런 이름을 핸들링하는 것에 대한 세부 사항이 있습니다.

## 5.14. Bypassing Filename encoding

#### Problem

기본 파일 이름 인코딩에 따라 디코딩이나 인코딩 된 적이 없는 `raw` 파일 이름을 사용하여 파일 I/O 작업을 수행하길 원합니다.

#### Solution

기본적으로, 모든 파일 이름은 `sys.getfilesystemencoding()`에 의해 반환된 텍스트 인코딩에 따라 인코딩과 디코딩됩니다.

```python
>>> sys.getfilesystemencoding()
'utf-8'
```

이 인코딩을 어떤 이유로 우회하길 원한다면 `raw` 바이트 문자열을 사용하여 파일 이름을 지정합니다.

```python
>>> # Write a file using a unicode Filename
>>> with open('jalape\xf1o.txt', 'w') as f:
...     f.write('Spicy!')
...
6
>>> # Directory listing (decoded)
>>> import os
>>> os.listdir('.')
['jalapeño.txt']
>>> # Directory listing (raw)
>>> os.listdir(b'.')        # Note: byte string
[b'jalapen\xcc\x83o.txt']
>>> # Open file with raw filename
>>> with open(b'jalapen\xcc\x83o.txt') as f:
...     print(f.read())
...
Spicy!
```

위 두 작업에서 볼 수 있듯이 바이트 문자열이 `open()`과 `os.listdir()`같이 파일에 관련된 함수에 제공될 때 파일 핸들링이 약간 변경됩니다.

#### Discussion

일반적인 상황에서, 일반 파일 이름 작업이 제대로 동작해야 하므로 파일 이름 인코딩과 디코딩에 대해 걱정해야 할 필요가 없습니다. 하지만 많은 운영체제가 사용자에게 인코딩 규칙을 따르지 않는 이름을 가진 파일을 만들기 위해 실수나 악의로 허용할 수 있습니다.
이런 파일 이름은 많은 파일과 함께 동작하는 Python 프로그램에 악영향을 줄 수 있습니다.

디렉터리를 읽고 디코딩 되지 않은 `raw` 바이트 같은 파일 이름과 함께 동작하면 프로그램의 편리성을 감수하더라더 이러한 문제를 피할 수 있습니다.

다음 장에 디코딩 되지 않은 파일 이름을 출력하는 장이 있습니다.

## 5.15. Printing Bad Filenames

#### Problem

프로그램이 디렉터리 목록을 수신했지만 파일 이름을 출력하려고 시도할 때 `UnicodeEncodeError` 예외와 `surrogates not allowed(대리자가 허용되지 않음)`라는 암호 메시지와 함께 충돌했습니다.

#### Solution

알 수 없는 원본 파일 이름을 출력할 때는 에러를 피하기 위해 다음 규칙을 사용하시기 바랍니다.

```python
def bad_filename(filename):
    return repr(filename)[1:-1]

try:
    print(filename)
except UnicodeEncodeError:
    print(bad_filename(filename))
```

#### Discussion

이 장은 파일 시스템을 조작해야 하는 프로그램과 관련하여 잠재적으로 희귀하지만 매우 귀찮은 문제에 대한 것입니다. 기본적으로, Python은 모든 파일 이름이 `sys.getfilesystemencoding()`에 의해 보고된 설정에 따라 인코딩 된다고 가정합니다.
하지만 어떤 파일 시스템은 인코딩 제한을 강제하지 않으므로 적절한 파일 이름 인코딩 없이 파일 생성을 허용합니다. 흔한 일은 아니지만 항상 일부 사용자가 어리석은 일을 하고 실수로 파일을 만들 위험이 있습니다.(버그가 있는 코드에서 잘못된 파일 이름을 `open()` 하는 등)

`os.listdir()`과 같은 명령을 실행할 때 잘못된 파일 이름은 Python `bind`에 남겨 둡니다. 잘못된 파일 이름을 버릴 수는 없습니다. 여전히 파일 이름을 적절한 텍스트 문자열로 바꿀 수도 없습니다. Python의 이 문제를 위한 해결책은 파일 이름에서 디코딩 될 수없는 바이트 값 `\xhh`을 가져와서 유니코드 문자 `\udchh`에 의해 표현되는 `surrogate encoding(대리자 인코딩)`이라 불리는 것으로 매핑하는 것입니다.
다음은 잘못된 파일 목록이 UTF-8 대신 Latin-1로 인코딩 된 파일 이름이 bäd.txt가 들어있는 것으로 보이는 방법의 예입니다.

```python
>>> import os
>>> files = os.listdir('.')
>>> files
['spam.py', 'b\udce4d.txt', 'foo.txt']
```

만일 파일 이름을 조작하거나 심지어 `open()`과 같은 함수에 전달하는 코드가 있을 때는 모든 것이 정상적으로 작동합니다. 이는 문제가 발생한 파일 이름을 출력하려는 경우에만 해당됩니다.(스크린이나 로그를 작성하는 등에 출력하는 경우) 특히, 앞의 목록을 출력하려고 시도하는 경우에는 프로그램이 충돌하게 됩니다.

```python
>>> for name in files:
...     print(name)
...
spam.py
UnicodeEncodeError: surrogates not allowed
```

충돌하는 이유는 `\udce4`가 기술적으로 잘못된 유니코드라는 것입니다. 실제로는 `surrogate` 쌍으로 알려진 두 문자 조합의 두 번째 절반입니다.
하지만 첫 번째 절반이 사라졌기 때문에 유효하지 않은 유니코드입니다. 그러므로 성공적인 출력을 위한 단 한 가지 방법은 잘못된 파일 이름일 때 올바른 조치를 취하는 것입니다.

```python
for name in files:
    try:
        print(name)
    except UnicodeEncodeError:
        print(bad_filename(name))
```

`bad_filename()` 함수로 무엇을 할 지 선택은 여러분에게 달려 있습니다.
다른 옵션은 다음과 같은 방법으로 값을 재 인코딩하는 것입니다.

```python
def bad_filename(filename):
    temp = filename.encode(sys.getfilesystemencoding(), errors='surrogateescape')
    return temp.decode('latin-1')
```

이 버전은 다음과 같이 출력을 생성합니다.

```
spam.py
bäd.txt
foo.txt
```

이 장은 대부분의 독자들이 무시하게 될 것입니다. 하지만 파일 이름과 시스템과 함께 의존하게 되는 작업이 필요한 `mission-critical`한 스크립트를 작성할 경우에는 생각해 볼만한 문제입니다.
아니면 주말내내 사무실에 다시 전화하여 겉으로 보기 어려운 에러를 디버깅할 수도 있습니다.

## 5.16. Adding or Changing the Encoding of an Already Open File

#### Problem

파일을 닫지 않고 먼저 이미 열린 파일의 유니코드 인코딩을 추가하거나 변경하고 싶습니다.

#### Solution

이미 존재하는 바이너리 모드로 열린 파일 객체에 유니코드 인코딩/디코딩을 추가하려면 `io.TextIOWrapper()` 객체와 함께 `wrap`합니다.

```python
import urllib.request
import io

u = urllib.request.urlopen('http://www.python.org')
f = io.TextIOWrapper(u, encoding='utf-8')
text = f.read()
```

만일 이미 열린 텍스트 모드 파일의 인코딩을 변경하려고 하면 이미 존재하는 텍스트 인코딩 레이어를 제거한 다음 새 것으로 대체하기 위한 인코딩 `detach()` 메서드를 사용합니다.
다음은 `sys.stdout`에서 인코딩을 변환하는 예제입니다.

```python
>>> import sys
>>> sys.stdout.encoding
'UTF-8'
>>> sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='latin-1')
>>> sys.stdout.encoding
'latin-1'
```

이러면 터미널의 출력이 깨질 수도 있습니다. 이는 단지 설명하기 위한 것입니다.
