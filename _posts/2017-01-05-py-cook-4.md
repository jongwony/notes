---
layout: post
title: Python cookbook Chapter 4 한글
tags: ['python', 'docs', 'iterator', 'generator', '한글']
progress: 99
---

<div id='index-table'>
<h2>4. Iterators and Generators</h2>
</div>

- - -


<div class='warn'>
이 문서는 Python Coobook 3rd edition - O'REILLY, David Beazley & Brian K. jones 를 참고한 것이며 개인적인 번역으로 인한 오역이 있을 수 있습니다.<br> <a href="//wikidocs.net/book/1">Python을 완전히 처음 접하는 경우</a>에는 적합하지 않습니다.<br>
</div>

`iteration`은 Python의 가장 강력한 기능 중 하나입니다. 높은 레벨에서, `sequence` 에서 항목을 처리하는 방법인 `iteration`이 간단하게 보일 수 있습니다. 하지만 자신만의 `iterator` 객체를 생성하거나 `itertools` 모듈에서 유용한 `iteration` 패턴이 적용되거나, `generator` 함수를 생성 하는 등 가능한 것들이 훨씬 많습니다.
이 챕터는 `iteration`을 포함하는 일반적인 문제를 다룹니다.

## 4.1. Manually Consuming an iterator

#### Problem

`iterable` 객체의 항목을 처리하지만 어떤 이유든 간에 `for` 루프를 사용하고 싶지 않거나 할 수 없습니다.

#### Solution

`iterable` 객체를 수동으로 `consume(소비)`하려면 `next()` 함수를 사용하고 `StopIteration` 예외를 `catch`하는 코드를 작성 합니다. 예를 들어 이 예제는 파일로부터 수동으로 라인을 읽습니다.

```python
with open('/etc/passwd') as f:
    try:
        while True:
            line = next(f)
            print(line, end='')
    except StopIteration:
        pass
```

일반적으로 `StopIteration`은 `iteration`의 끝을 나타낼 때(signal) 사용됩니다. 하지만 `next()`를 수동적으로 사용하게 될 경우(위와 같이) `None`과 같은 끝을 나타내는 값(terminating value)을 대신 반환하도록 해야합니다.

```python
with open('/etc/passwd') as f:
    while True:
        line = next(f, None)
        if line is None:
            break
        print(line, end='')
```

#### Discussion

대부분의 경우에 `for` 문은 `iterable` 객체를 소비하는데 사용됩니다. 하지만 매 순간마다, 문제가 `iteration` 메커니즘 내에서 좀 더 정밀한 제어가 요구됩니다. 그러므로 실제로 무엇이 일어나는지 아는 것이 좋습니다.

다음 대화식 예제는 iteration이 일어나는 동안의 기본적인 메커니즘을 보여줍니다.

```python
>>> items = [1, 2, 3]
>>> # Get the iterator
>>> it = iter(items)        # Invokes items.__iter__()
>>> # Run the iterator
>>> next(it)                # Invokes it.__next__()
1
>>> next(it)
2
>>> next(it)
3
>>> next(it)
StopIteration
```

다음 장에서 `iteratation` 테크닉이 확장되고 기본적인 `iterator` 프로토콜 기본 지식을 배웁니다.(assumed) 이 첫 장을 기억에서 제거하시기 바랍니다.

## 4.2. Delegating iteration

#### Problem

`list`, `tuple`, 또는 또다른 `iterable` 객체를 내부적으로 보관하는 커스텀 `container` 객체를 생성했습니다. 새 `container`에 `iteration` 동작을 하고 싶습니다.

#### Solution

일반적으로 해야할 것은 내부적으로 보관된 `container`에 `iteration`을 `delegate(위임)`하는 `__iter__()` 메서드를 정의하는 것입니다.

```python
class Node:
    def __init__(self, value):
        self._value = value
        self._children = []

    def __repr__(self):
        return 'Node({!r})'.format(self._value)

    def add_child(self, node):
        self.children.append(node)

    def __iter__(self):
        return iter(self._children)

# Example
if __name__ == '__main__':
    root = Node(0)
    child1 = Node(1)
    child2 = Node(2)
    root.add_child(child1)
    root.add_child(child2)
    for ch in root:
        print(ch)
    # Node(1), Node(2)
```

이 코드에서는 `__iter__()` 메서드가 단순히 `iteration` 요청을 내부적으로 보관된 `_children`에 전달합니다.

#### Discussion

Python의 `iterator` 프로토콜은 `__iter__()`가 실제 `iteration`을 수행하기 위해 `__next__()` 메서드를 구현하는 특별한 `iterator` 객체를 반환하기 위해 필요합니다. 만일 하고있는 모든 일에서 또 다른 `container`의 내용물을 통해 `iterating`하려면 어떻게 작동하는지의 내부적인 세부사항에 대하여 걱정할 필요가 없습니다.
해야할 모든 일은 `iteration` 요청을 따라서 전달하는 것입니다.

여기서 `iter()` 함수의 사용은 코드를 정리하는 약간의 지름길(shortcut)입니다. `iter(s)`는 단순히 `len(s)`가 `s.__len__()`을 부르는 것과 같은 방법으로 `s.__iter__()`를 호출함으로써 내부의 `iterator`를 반환합니다.

## 4.3. Creating New Iteration Patterns with Generators

#### Problem

보통의 `built-in`함수(`range()`, `reversed()` 등)와는 다른 커스텀 `iteration` 패턴을 구현하고 싶습니다.

#### Solution

만일 새로운 종류의 `iteration` 패턴을 구현하려면 `generator` 함수를 사용하여 정의합니다. 다음은 `floating-point` 수의 범위를 생성하는 `generator` 입니다.

```python
def frange(start, stop, increment):
    x = start
    while x < stop:
        yield x
        x += increment
```

이 함수를 사용하기 위해 `for` 루프를 사용하여 `iterate` 하거나 `iterable` 객체(`sum()`, `list()` 등)를 소비하는 다른 함수를 함께 사용합니다. 예를 들면

```python
>>> for n in frange(0, 4, 0.5):
...     print(n)
0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
>>> list(frange(0, 1, 0.125))
[0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875]
```

#### Discussion

함수에서 단순한 `yield`문의 존재가 `generator`로 변환시켜줍니다. 일반적인 함수와는 다르게 `generator`는 `iteration`에만 응답하는 동작을 합니다. 다음은 이런 함수들이 동작하는 방법에 대한 내부적인 메커니즘을 볼 수 있는 실험입니다.

```python
def countdown(n):
    print('Starting to count from', n)
    while n > 0:
        yield n
        n -= 1
    print('Done!')
# Create the generator, notice no output appears
c = countdown(3)
# Run to first yield and emit a value
print(next(c))         # 첫번째 yield의 반환 값
# Starting to count from 3
# 3
# Run to the next yield
print(next(c))
# 2
print(next(c))
# 1
print(next(c))
# Done!
# StopIteration
```

중요한 기능은 `generator` 함수가 `next` 작업에만 응답하여 `iteration`을 수행한다는 것입니다. 한번 `generator` 함수가 반환되면 `iteration`은 정지합니다. 하지만 보통 `iterate`에 사용되는 `for`문은 이런 세부 사항을 처리하므로 일반적으로 신경을 쓰지 않아도 됩니다.

## 4.4. Implementing the Iterator Protocol

#### Problem

`iteration`을 지원하려는 커스텀 객체를 생성하고 있지만 `iterator` 프로토콜을 구현하는 쉬운 방법을 찾습니다.

#### Solution

지금까지 가장 쉬운 `iteration` 객체의 구현 방법은 `generator` 함수를 사용하는 것입니다. [4.2장](#delegating-iteration)에서 `Node` 클래스는 트리 구조를 표현하기 위해 제시되었습니다. 아마 `depth_first` 패턴의 노드를 순회하는 `iterator`를 구현하게 된다면 다음과 같이 할 수 있을 것입니다.

```python
class Node:
    def __init__(self, value):
        self._value = value
        self._children = []

    def __repr__(self):
        return 'Node({!r})'.format(self._value)

    def add_child(self, node):
        self._children.append(node)

    def __iter__(self):
        return iter(self._children)

    def depth_first(self):
        yield self
        for c in self:
            yield from c.depth_first()

# Example
if __name__ == '__main__':
    root = Node(0)
    child1 = Node(1)
    child2 = Node(2)
    child1_1 = Node(3)
    child1_2 = Node(4)
    child2_1 = Node(5)

    root.add_child(child1)
    root.add_child(child2)
    child1.add_child(child1_1)
    child1.add_child(child1_2)
    child2.add_child(child2_1)

    for ch in root.depth_first():
        print(ch)
    # Node(0) Node(1) Node(3) Node(4) Node(2) Node(5)
```

이 코드에서 `depth_first()` 메서드를 간단히 읽고 설명할 수 있습니다. 먼저 자신을 `yield` 하고 각 `child`에 대해 `iterate` 하면서 `child`의 `depth_first()`(`yield from`이 사용된) 메서드에 의해 생성된 항목을 `yielding` 합니다.

#### Discussion

Python의 `iterator` 프로토콜은 `__next__()` 작업으로 구현되고 종료 신호에 `StopIteration` 예외를 사용하는 특별한 `iterator` 객체를 반환하기 위해 `__iter__()`가 필요합니다. 하지만 이런 객체를 구현하는 것은 종종 지저분한 일이 될 수 있습니다. 예를 들어 다음 코드는 `iterator` 클래스와 연관지어 사용되는 `depth_first()` 메서드의 대안을 보여줍니다.

```python
class Node:
    def __init__(self, value):
        self._value = value
        self._children = []

    def __repr__(self):
        return 'Node({!r})'.format(self._value)

    def add_child(self, other_node):
        self._children.append(other_node)

    def __iter__(self):
        return iter(self._children)

    def depth_first(self):
        return DepthFirstIterator(self)

# Depth First traversal
class DepthFirstIterator(object):
    def __init__(self, start_node):
        self._node = start_node
        self._children_iter = None
        self._child_iter = None

    def __iter__(self):
        return self

    def __next__(self):
        # Return myself if just started; create an iterator for children
        if self._children_iter is None:
            self._children_iter = iter(self._node)
            return self._node

        # if processing a child, return its next items
        elif self._child_iter:
            try:
                nextchild = next(self._child_iter)
                return nextchild
            except StopIteration:
                self._child_iter = None
                return next(self)
        # Advance  to the next child and start its iteration
        else:
            self._child_iter = next(self._children_iter).depth_first()
            return next(self)
```

`DepthFirstIterator` 클래스는 `generator` 버전과 동일한 방법으로 동작하지만 `iterator`가 `iteration` 프로세스에서 많은 복잡한 상태를 유지하기 때문에 지저분해집니다. 솔직히 아무도 저런 마음이 굽은(mind-bending) 코드를 좋아하지 않을 것입니다. `iterator`를 `generator`로써 정의하고 그것으로 끝내시기 바랍니다.

## 4.5. Iterating in Reverse

#### Problem

`sequence` 를 거꾸로 `iterate`하는 코드를 원합니다.

#### Solution

`built-in reversed()` 함수를 사용합니다. 예를 들면

```python
>>> a = [1, 2, 3, 4]
>>> for x in reversed(a):
...     print(x)
...
4
3
2
1
```

`reversed iteration`은 오로지 문제의 객체가 결정될 수 있는 크기를 가지거나 `__reversed__()` 특별한 메서드로 구현되는 객체에서만 작동합니다. 이 조건들 중 하나가 만족될 수 없다면 객체를 먼저 `list` 로 변환해야 합니다.

```python
f = open('somefile')
for line in reversed(list(f)):
    print(line, end='')
```

위와 같이 `list iterable` 객체로 변환하는 것은 이 객체가 크다면 메모리를 많이 소비하는 것에 유의하시기 바랍니다.

#### Discussion

많은 프로그래머들이 `reversed iteration`을 `__reversed__()` 메서드로 구현하면 사용자가 정의한 클래스에서 커스터마이즈 할 수 있다는 것을 모릅니다.

```python
class Countdown:
    def __init__(self, start):
        self.start = start

    def __iter__(self):
        n = self.start
        while n > 0:
            yield n
            n -= 1

    # Reverse iterator
    def __reversed__(self):
        n = 1
        while n <= self.start:
            yield n
            n += 1
```

`reversed iterator`를 정의하는 것은 더이상 데이터를 `list`로 가져올 필요가 없고 `list`에서 거꾸로 `iterate`할 필요 없이 코드를 좀 더 효율적으로 만들어 줍니다.

## 4.6. Defining Generator Functions with Extra state

#### Problem

`generator` 함수를 정의하고 싶은데 사용자에게 어떻게든 노출하게 되는 추가적인 상태를 포함해야 합니다.

#### Solution

사용자에게 추가적인 샃태를 노출하기 위한 `generator`를 원한다면 클래스로써 쉽게 구현할 수 있고 `generator` 함수 코드를 `__iter__()` 메서드로 집어 넣을 수 있음을 잊지 말아야 합니다.

```python
from collections import deque

class linehistory:
    def __init__(self, lines, histlen=3):
        self.lines = lines
        self.history = deque(maxlen=histlen)

    def __iter__(self):
        for lineno, line in enumerate(self.lines, 1):
            self.history.append((lineno, line))
            yield line

    def clear(self):
        self.history.clear()
```

이 클래스를 사용하려면 일반적인 `generator` 함수를 다루어야 합니다. 하지만 인스턴스를 생성하기 때문에 `history` 속성 또는 `clear()` 메서드 같은 내부 속성에 접근할 수 있게 됩니다.

```python
with open('somefile.txt') as f:
    lines = linehistory(f)
    for line in lines:
        if 'python' in line:
            for lineno, hline in lines.history:
                print('{}:{}'.format(lineno, hline), end='')
```

#### Discussion

`generator`는 함수만으로 모든 것을 하려고 하는 함정에 빠지기 쉽습니다. 이는 `generator` 함수가 다른 프로그램의 부분과 비정상적인 방법으로(속성 노출, 메서드 호출 간 제어 허용 등) 상호작용 해야 할 때 덜 복잡한 코드를 이끌어낼 수 있습니다. 이 경우에는 단지 위와 같이 클래스 정의만 사용합니다. `__iter__()` 메서드의 `generator`를 정의하는 것은 알고리즘을 사용하는 방법에 대해서는 아무 것도 바꿀 수 없습니다. 클래스의 한 부분이라는 사실은 속성과 메서드를 사용자에게 쉽게 제공할 수 있게 해줍니다.

위의 메서드를 사용한 한 가지 미묘한 점은 `for` 루프와는 다른 기술을 사용하여 `iteration`을 수행하려는 경우 `iter()` 를 호출하는 추가 단계가 필요할 수 있다는 것입니다.

```python
>>> f = open('somefile.txt')
>>> lines = linehistory(f)
>>> next(lines)
TypeError
>>> # Call iter() first, then start iterating
>>> it = iter(lines)
>>> next(it)
'hello world\n'
>>> next(it)
'this is a test\n'
```

## 4.7. Taking a Slice of an iterator

#### Problem

`iterator`로 생성된 데이터를 `slice` 하고 싶은데 일반적인 `slice operator`가 동작하지 않습니다.

#### Solution

`itertools.islice()` 함수는 `iterator`와 `generator`의 `slice`를 다루기 위한 완벽히 알맞은 함수입니다.

```python
def count(n):
    while True:
        yield n
        n += 1

c = count(0)
c[10:20]
# TypeError: 'generator' object is not subscriptable

# Now using islice()
import itertools
for x in itertools.islice(c, 10, 20):
    print(x)
# 10 11 12 ... 19
```

#### Discussion

`iterator`와 `generator`는 길이에 대한 정보를 알 수 없기 때문에(인덱싱도 구현이 되어 있지 않습니다.) 일반적으로 `slice` 될 수 없습니다. `islice()`의 결과는 자른 `slice` 항목으로 생성된 `iterator`지만 모든 시작 인덱스 항목까지 소비하고 버림으로써 이를 수행합니다. 그 다음 `islice` 객체가 종료 인덱스에 도달할 때 까지 추가 항목이 생성됩니다.

`islice()`가 제공된 `iterator`에서 데이터를 소비한다는 점을 강조하는 것이 중요합니다. `iterator`는 되돌리기가 불가능하므로 고려해야 할 사항입니다. 되돌리는 것이 중요하다면 아마 데이터를 `list`로 먼저 바꾸어야 할 것입니다.

## 4.8. Skipping the First Part of an iterable

#### Problem

`iterable`의 항목을 반복하고 싶지만 처음 몇 항목은 관심이 없고 제거하고 싶습니다.

#### Solution

`itertools` 모듈은 이 일을 다루기 위해 사용될 수 있는 몇몇 함수들을 가지고 있습니다. 첫 번째는 `itertools.dropwhile()` 함수입니다. 이를 사용하기 위해 함수와 `iterable` 객체를 지원합니다. 반환된 `iterator`는 제공된 함수가 `True`를 반환하는 한 `sequence`에서 처음 항목을 버립니다. 나중에, 전체 `sequence`가 생성됩니다.

예를 들면 일련의 주석 라인으로 시작하는 파일을 읽는다고 가정합니다.

```python
with open('/etc/passwd') as f:
    for line in f:
        print(line, end='')
```

모든 초기 주석 행을 건너 뛰려면 다음과 같은 방법으로 할 수 있습니다.

```python
from itertools import dropwhile
with open('/etc/passwd') as f:
    for line in dropwhile(lambda line: line.startswith('#'), f):
        print(line, end='')
```

이 예제는 테스트 함수에 따라 첫 항목을 건너뛰는 것을 기반으로 합니다. 정확히 몇 개의 항목을 건너뛰는 일이 일어났는지 알기 위해서는 `itertools.islice()`를 대신 사용할 수 있습니다.

```python
from itertools import islice
items = ['a', 'b', 'c', 1, 4, 10, 15]
for x in islice(items, 3, None):
    print(x)
# 1 4 10 15
```

이 예제에서 `islice()`의 마지막 `None` 인수는 처음 세 항목을 초과하는 모든 항목을 처음 세 항목이 아닌 반대로 표시하기 위해 필요합니다.(예를 들어 `[3:]`의 반대로 `[:3]`을 `slice`하는 것입니다.)

#### Discussion

`dropwhile()`과 `islice()` 함수는 주로 다음과 같은 지저분한 코드 작성을 피하기 위해 사용할 수 있는 편리한 함수입니다.

```python
with open('/etc/passwd') as f:
    # Skip over initial comments
    while True:
        line = next(f, '')
        if not line.startswith('#'):
            break

    # Process remaining lines
    while line:
        # Replace with useful processing
        print(line, end='')
        line = next(f, None)
```

`iterable` 객체의 첫 부분을 제거하는 것은 모든 것을 단순히 필터링 하는 것과는 약간 다릅니다. 예를 들어 이 장의 첫 부분은 다음과 같이 다시 쓰일 수 있습니다.

```python
with open('/etc/passwd') as f:
    lines = (line for line in f if not line.startswith('#'))
    for line in lines:
        print(line, end='')
```

이는 명백하게 시작 부분의 주석 라인을 제거하지만 또한 모든 파일을 통해 이러한 모든 행을 제거할 것입니다. 반면에 Solution은 항목이 더이상 제공된 테스트를 만족하지 않을 때까지 항목을 제거하게 됩니다. 그 후 모든 후속 항목은 필터링이 되지 않은 채 반환됩니다.

마지막으로 하지만 적어도 이 장이 크기를 미리 결정할 수 없다는 것을 포함하여 모든 `iterable` 객체에서 동작한다는 점을 강조해야합니다.
이는 `generator`와 `file` 그리고 비슷한 종류의 객체를 포함합니다.

## 4.9. Iterating Over All Possible Combinations or Permutations

#### Problem

항목의 `collection`의 가능한 모든 `combination(조합)` 또는 `permutation(순열)`을 `iterate`하고 싶습니다.(수학에서 다루는 순열 및 조합과 동일합니다.)

#### Solution

`itertools` 모듈은 이 작업을 위한 세가지 함수를 제공합니다. 이들 중 첫번째는 `itertoos.permutations()`이며 항목의 `collection`을 다루어 모든 가능한 `permutation` 항목을 재배열하는 `tuple`의 `sequence`를 생성합니다.(즉, 모든 가능한 구성으로 셔플합니다.) 예를 들면

```python
items = ['a', 'b', 'c']
from itertools import permutations
for p in permutations(items):
    print(p)
```

작은 길이의 모든 `permutation`을 원한다면 선택적인 길이 인수를 줄 수 있습니다.

```python
for p in permutations(items, 2):
    print(p)
```

`input`으로 부터 항목의 `combination`을 생성하기 위해 `itertools, combinations()`를 사용합니다.

```python
from itertools import combinations
for c in combinations(items, 3):
    print(c)

for c in combinations(items, 2):
    print(c)

for c in combinations(items, 1):
    print(c)
```

`combinations()`에서는 실제로 항목들의 순서가 고려되지 않습니다. 즉, `('a', 'b')`의 `combination`은 `('b', 'a')`(이는 생성되지 않습니다.)와 동일하게 취급됩니다.

`combination`을 생성할 때 고른 항목은 가능한 후보의 `collection`으로부터 제거됩니다. (즉 `'a'`는 이미 선택 되었으므로 고려 대상에서 제거됩니다.) `itertools.combinations_with_replacement()` 함수는 이를 완화하고 동일한 항목이 한번 이상 선택되게 허용합니다.

```python
for c in combinations_with_replacement(items, 3):
    print(c)
```

#### Discussion

이 장은 `itertools` 모듈에서 발견되는 강력한 점의 일부를 보여줍니다. 비록 직접 `permutation`과 `combination`을 생성하는 특정 코드를 작성할 수 있지만 그렇게 하는 것은 생각한 것 보다 더 많은 것을 요구하게 됩니다. 복잡한 `iteration` 문제에 직면한 것 같다면 항상 `itertools`를 먼저 들여다 보시길 바랍니다. 일반적인 문제라면 이미 가능한 해결책을 찾은 기회입니다.

## 4.10. Iterating Over the Index-Value Pairs of a Sequence

#### Problem

`sequence`를 `iterate`하길 원하지만 `seuence`의 어떤 요소가 현재 처리되고 있는지 추적하고 싶습니다.

#### Solution

`built-in enumerate()` 함수는 꽤 멋지게 `handle`합니다.

```python
my_list = ['a', 'b', 'c']
for idx, val in enumerate(my_list):
    print(idx, val)
```

`canonical(정식)` 줄 번호로 출력하고 싶다면(전형적으로 0 대신 1로 시작) `start` 인수를 넘겨 줄 수 있습니다.

```python
my_list = ['a', 'b', 'c']
for idx, val in enumerate(my_list, 1):
    print(idx, val)
```

이 경우는 오류 메시지에 줄 번호를 사용하려는 경우 파일의 줄 번호를 추적할 때 특히 유용합니다.

```python
def parse_data(filename):
    with open(filename, 'rt') as f:
        for lineno, line in enumerate(f, 1):
            fields = line.split()
            try:
                count = int(fields[1])
                ...
            except ValueError as e:
                print('Line {}: Parse error: {}'.format(lineno, e))
```

`enumerate()`는 특정 값의 발생에 대한 `list`의 오프셋을 추적하는 예로 유용(handy)할 수 있습니다. 그래서 파일의 단어를 발생하는 줄에 매핑하려면 `enumerate()`를 사용하여 각 단어를 파일에서 찾은 줄의 오프셋 줄에 매핑하는 것을 쉽게 할 수 있게됩니다.

```python
word_summary = defaultdict(list)

with open('myfile.txt', 'r') as f:
    lines = f.readlines()

for idx, line in enumerate(lines):
    # Create a list of words in current line
    words = [w.strip().lower() for w in line.split()]
    for word in words:
        word_summary[word].append(idx)
```

파일을 처리한 후에 `word_summary`를 출력 하려면 `dictionary`가 될 것이고(`defaultdict`라고 명시된 것 처럼) 각 단어에 대한 `key`를 가지고 있을 것입니다. 각 단어의 키에 대한 `value`는 발생한 단어의 줄 수의 `list`가 될 것입니다. 단어가 한 줄에 두 번 나타나면 해당하는 줄의 번호가 두번 나열되어 텍스트에 대한 간단한 `metric`을 식별할 수 있는 가능성을 만들어 줍니다.

#### Discussion

`enumerate()`는 자신의 `counter` 변수를 유지하려는 상황에 적합한 지름길이 됩니다. 다음과 같이 코드를 쓸 수 있습니다.

```python
lineno = 1
for line in f:
    # Process line
    ...
    lineno += 1
```

하지만 일반적으로 좀 더 우아한 방법(에러 발생도 적은)으로 `enumerate()`를 대신 사용할 수 있습니다.

```python
for lineno, line in enumerate(f):
    # Process line
    ...
```

`enumerate()`에 의해 반환되는 값은 `enumerate` 객체의 인스턴스이며 `counter`와 지나간 `sequence`에서 `next()`를 호출함으로써 반환된 값으로 구성되는 연속된 `tuple`을 반환하는 `iterator`입니다.

비록 사소한 부분일지라도 때로는 `unpack`된 `tuple sequence`에 `enumerate()`를 적용할 때 순회하기 쉽다는 것을 언급할 가치가 있습니다.

```python
data = [ (1, 2), (3, 4), (5, 6), (7, 8) ]

# Correct!
for n, (x, y) in enumerate(data):
    ...

# Error!
for n, x, y in enumerate(data):
    ...
```

## 4.11. Iterating Over Multiple Sequences Simultaneously

#### Problem

한번에 한 `sequence` 이상 포함된 항목을 `iterate` 하고 싶습니다.

#### Solution

한 `sequence` 이상 동시에 `iterate` 하려면 `zip()` 함수를 사용합니다.

```python
>>> xpts = [1, 5, 4, 2, 10, 7]
>>> ypts = [101, 78, 37, 15, 62, 99]
>>> for x, y, in zip(xpts, ypts):
...     print(x, y)
...
1 101
5 78
4 37
2 15
10 62
7 99
```

`zip(a, b)`는 `a`로 부터 `x`, `b`로 부터 `y`를 취하여 `tuple (x, y)`를 생성하는 `iterator`를 생성함으로써 작동합니다. `iteration`은 `input sequence` 중 하나가 모두 소모될 때 중지 됩니다. 그러므로 `iteration`의 길이는 가장 짧은 길이의 `input`과 동일한 길이가 됩니다.

```python
>>> a = [1, 2, 3]
>>> b = ['w', 'x', 'y', 'z']
>>> for i in zip(a, b):
...     print(i)
...
(1, 'w')
(2, 'x')
(3, 'y')
```

만일 이를 바라던 것이 아니었다면 `itertools.zip_longest()`를 대신 사용하시기 바랍니다.

```python
>>> from itertools import zip_longest
>>> for i in zip_longest(a, b):
...     print(i)
...
(1, 'w')
(2, 'x')
(3, 'y')
(None, 'z')
>>> for i in zip_longest(a, b, fillvalue=0):
...     print(i)
...
(1, 'w')
(2, 'x')
(3, 'y')
(0, 'z')
```

#### Discussion

`zip()`은 일반적으로 데이터를 쌍으로 할 때마다 사용됩니다. 예를 들어 다음과 같이 컬럼의 `header`와 `list`가 있다고 가정합니다.

```python
headers = ['name', 'shares', 'price']
values = ['ACME', 100, 490.1]
```

`zip()`을 사용함으로써 `value`를 쌍으로 다음과 같이 `dictionary`를 만들 수 있습니다.

```python
s = dict(zip(headers, values))
```

대안으로 출력을 생성하려면 다음과 같이 코드를 작성할 수 있습니다.

```python
for name, val in zip(headers, values):
    print(name, '=', val)
```

일반적이지는 않지만 `zip(`은 둘 이상의 `sequence`를 `input`으로 전달 할 수 있습니다. 이런 경우에 결과 `tuple`은 `input sequence`의 수와 같은 수의 항목을 가지고 있습니다.

```python
>>> a = [1, 2, 3]
>>> b = [10, 11, 12]
>>> c = ['x', 'y', 'z']
>>> for i in zip(a, b, c):
...     print(i)
...
(1, 10, 'x')
(2, 11, 'y')
(3, 12, 'z')
```

마지막으로 하지만 적어도 `zip()`이 결과로 `iterator`를 생성하는 것을 강조하는 것이 중요합니다. 만일 짝지어진 값들을 `list`로 저장해야한다면 `list()` 함수를 사용합니다.

```python
>>> zip(a, b)
<zip object at 0x...>
>>> list(zip(a, b))
[(1, 10), (2, 11), (3, 12)]
```

## 4.12. Iterating on Items in Separate Containers

#### Problem

많은 객체에서 동일한 작업을 수행하지만 객체가 다른 `container`에 속했고 코드 가독성을 잃지 않으면서 중첩된 루프를 피하고 싶습니다.

#### Solution

`itertools.chain()` 메서드는 이 작업을 단순화하는 데 사용될 수 있습니다. `iterable` 객체의 `list`를 `input`으로, 실제로 여러 컨테이너에서 동작하는 사실을 효과적으로 마스크하는 `iterator`를 반환합니다.

```python
from itertools import chain
a = [1, 2, 3, 4]
b = ['x', 'y', 'z']
for x in chain(a, b):
    print(x)
# 1 2 3 4 x y z
```

`chain()`의 일반적인 사용은 모든 항목에 한 번씩 어떤 작업을 수행할 수 있는 프로그램에 있지만 항목은 다른 `working set`에 `pool(저장)`됩니다. 예를 들면

```python
# Various working sets of items
active_items = set()
inactive_items = set()

# Iterate over all items
for item in chain(active_items, inactive_items):
    # Process item
    ...
```

이 Solution은 다음과 같이 따로 두 루프를 사용하는 것 보다 훨씬 더 우아합니다.

```python
for item in active_items:
    # Process item
    ...

for item in inactive_items:
    # Process item
    ...
```

#### Discussion

`itertools.chain()`은 하나 이상의 `iterable` 객체를 인자로 받습니다. 그런 다음 연속적으로 소비되고 제공된 각 `iterable` 객체로 생성된 항목을 반환한 `iterator`가 생성됨으로써 동작하게 됩니다.
미묘한 차이지만 `chain()`이 먼저 `sequence`를 결합하고 `iterate`하는 것 보다 좀 더 효율적입니다.

```python
# Inefficent
for x in a + b:
    ...

# Better
for x in chain(a, b):
    ...
```

첫 번째 케이스는 `a + b`가 완전히 새 `sequence`를 생성하고 추가로 `a + b`가 동일한 타입을 필요로 합니다. `chain()`은 이런 작업 없이도 수행할 수 있고 `input sequence`가 크고 문제의 `iterable` 객체가 다른 타입일 때 쉽게 적용된다면 메모리 문제와 함께 훨씬 더 효율적입니다.

## 4.13. Creating Data Processing Pipelines

#### Problem

`Unix`의 파이프와 유사한 `pipeline` 데이터 처리 스타일로 데이터를 반복적으로 처리하려고합니다. 예를 들어 거대한 양의 데이터를 처리할 필요가 있지만 메모리에 완전히 들어갈 수 없습니다.

#### Solution

`generator` 함수는 `pipeline` 처리하기 위한 좋은 구현 방법입니다. 에를 들면 거대한 로그 파일의 디렉터리를 처리한다고 가정합니다.

```
foo/
    access-log-012007.gz
    access-log-022007.gz
    access-log-032007.gz
    ...
    access-log-012008
bar/
    access-log-092007.bz2
    ...
    access-log-022008
```

각 파일은 다음과 같은 데이터 라인을 포함한다고 가정합니다.

```
124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] "GET /robots.txt ..." 200 71
210.212.289.67 - - [10/Jul/2012:00:18:51 -0500] "GET /ply/ ..." 200 11875
210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] "GET /favicon.ico ..." 404 369
61.135.216.105 - - [10/Jul/2012:00:20:04 -0500] "GET /blog/atom.xml ..." 304 -
...
```

이런 파일들을 처리하기 위해 자체 포함된 특정 작업을 수행하는 작은 `generator` 함수의 `collection`을 정의할 수 있습니다.

```python
import os
import fnmatch
import gzip
import bz2
import re

def gen_find(filepat, top):
    '''
    Find all filenames in a directory tree that match a shell wildcard pattern
    '''
    for path, dirlist, filelist in os.walk(top):
        for name in fnmatch.filter(filelist, filepat):
            yield os.path.join(path, name)

def gen_opener(filenames):
    '''
    Open a sequence of filenames one at a time producing file object.
    The file is closed immediately when proceeding to the next iteration.
    '''
    for filename in filenames:
        if filename.endswith('.gz'):
            f = gzip.open(filename, 'rt')
        elif filename.endswith('bz2'):
            f = bz2.open(filename, 'rt')
        else:
            f = open(filename, 'rt')
        yield f
        f.close()

def gen_concatenate(iterators):
    '''
    Chain a sequence of iterators together into a single sequence.
    '''
    for it in iterators:
        yield from it

def gen_grep(pattern, lines):
    '''
    Look for a regex pattern in a sequence of lines
    '''
    pat = re.compile(pattern)
    for line in lines:
        if pat.search(line):
            yield line
```

이제 이러한 함수를 쉽게 `stack(쌓아서)`해서 `pipeline` 처리를 만들 수 있습니다. 예를 들면 모든 `python`을 포함하는 줄의 로그를 찾기 위해 다음과 같이 할 수 있습니다.

```python
lognames = gen_find('access-log*', 'www')
files = gen_opener(lognames)
lines = gen_concatenate(files)
pylines = gen_grep('(?i)python', lines)
for line in pylines:
    print(line)
```

`pipeline`을 좀 더 확장하려면 `generator` 표현식에서 데이터를 공급할 수도 있습니다. 예를 들면 이 버전은 전송된 바이트의 수를 찾고 총 합을 계산합니다.

```python
lognames = gen_find('access-log*', 'www')
files = gen_opener(lognames)
lines = gen_concatenate(files)
pylines = gen_grep('(?i)python', lines)
bytecolumn = (line.rsplit(None, 1)[1] for line in pylines)
bytes = (int(x) for x in bytecolumn if x != '-')
print('Total', sum(bytes))
```

#### Discussion

`pipeline`된 방식의 데이터 처리는 `parsing`, 실시간 데이터 원본 읽기, 주기적인 `polling` 등을 포함한 다양한 문제를 잘 해결합니다.

코드를 이해하는 중에 `yield`문이 어떤 데이터 생성자로써 작동하는 반면에 `for` 루프는 데이터가 데이터 소비자로써 작동한다는 것을 캐치하는 것이 중요합니다. `generator`가 서로 쌓이기 시작하면 각 `yield`는 하나의 데이터 항목을 `iteration`과 함께 소비된 다음 `pipeline`의 단계로 공급하게 됩니다. 마지막 예제 중 `sum()` 함수는 실제로 전체 프로그램을 거친 `generator`의 `pipeline` 밖으로 한번에 한 항목을 `pulling` 합니다.

이 접근 방식의 한가지 좋은 점은 각 `generator` 함수가 작고 자체 포함되는 경향이 있다는 점입니다. 따라서 작성하고 유지하기 쉽습니다. 많은 경우에 일반적으로 다른 상황에서 재사용할 될 수 있도록 하는 목적이 있습니다.
구성요소를 서로 결합한 코드의 결과는 또한 쉽게 이해되는 편한 레시피로 읽을 수 있습니다.

메모리 효율성의 접근도 또한 과할 수 없습니다. 설명한 코드는 방대한 파일 디렉터리에서 사용되는 경우에도 여전히 동작합니다. 사실 프로세싱의 반복적인 특성 때문에 메모리가 거의 사용되지 않습니다.

`gen_concatenate()` 함수에 포함된 아주 약간 미묘한 부분이 있습니다. 이 함수의 목적은 `input sequence`를 하나의 긴 라인의 `sequence`로 함께 결합하는 것입니다. `itertools.chain()` 함수가 비슷한 기능을 수행하지만 모든 연결된 `iterable` 객체를 인수로 지정하는 것이 필요합니다. 이런 특별한 경우에 이렇게하면 `gen_opener() generator`를 완전히 소모하게하는 `lines = itertools.chain(*files)`과 같은 문장이 포함됩니다. `generator`가 **즉시 다음 `iteration` 단계에서 닫히는 일련의 열린 파일을 생성하기 때문에** `chain()`이 사용 될 수 없습니다. 위의 Solution은 이 문제를 방지합니다.

또한 `gen_concatenate()` 함수가 나타나는 것은 `subgenerator`로 `delegate`하기 위해 `yield from`이 사용됩니다. `yield from it`문은 간단하게 `it generator`로써 생성된 모든 값들을 `gen_concatenate()`로 나오게 합니다. 이에 대한 내용이 [4.14장](#flattening-a-nested-sequence)에 자세히 설명되어 있습니다.

마지막으로 `pipeline` 방식이 항상 모든 데이터 문제를 처리하는 것은 아니라는 점을 주목해야 합니다. 가끔 한 번에 모든 데이터를 처리해야 할 때도 있습니다. 하지만 이런 경우에서도 `generator pipeline`을 사용하면 문제를 논리적으로 일종의 `workflow`로 쪼개어 해결하는 방법이 될 수 있습니다.

David Beazley는 그의 ["Generator Tricks for Systems Programmers" 튜토리얼 프레젠테이션](//www.dabeaz.com/generators/)에 이런 기술들에 대해 광범위하게 저술했습니다. 더 많은 예제를 잠조하시기 바랍니다.

## 4.14. Flattening a Nested Sequence

#### Problem

단일 `list` 값들로 평준화 하려는 중첩된 `sequence`를 가지고 있습니다.

#### Solution

`yield from`문이 포함된 `recursive generator` 함수를 씀으로써 쉽게 해결할 수 있습니다.

```python
from collections import Iterable

def flatten(items, ignore_types=(str, bytes)):
    for x in items:
        if isinstance(x, Iterable) and not isinstance(x, ignore_types):
            yield from flatten(x)
        else:
            yield x

items = [1, 2, [3, 4, [5, 6], 7], 8]

# Produces 1 2 3 4 5 6 7 8
for x in flatten(items):
    print(x)
```

이 코드에서 `isinstance(x, Iterable)`은 간단하게 항목이 `iterable` 객체인지 보기 위한 체크를 합니다. 만약 그렇다면 `yield from`이 모든 값들을 `subroutine`으로써 내보내기 위해 사용됩니다. 마지막 결과는 중첩되지 않은 단일 `sequence`가 출력됩니다.

추가 인수인 `ignore_types`와 `not isinstance(x, ignore_types)` 체크는 문자열과 바이트가 `iterable` 객체로 해석되고 개별 문자로 확장되는 것을 예방합니다. 이는 문자열의 중첩 `list`에서도 대부분의 사람들이 기대하는 방법으로 동작 할 수 있습니다.

```python
items = ['Dave', 'Paula', ['Thomas', 'Lewis']]
for x in flatten(items):
    print(x)
# Dave Paula Thomas Lewis
```

#### Discussion

`yield from`문은 다른 `generator`를 `subroutine`으로써 호출하는 `generator`를 쓰길 원하는 경우에 사용하는 좋은 축약어입니다.
이를 사용하지 않는다면 추가로 `for` 루프를 사용하는 코드를 써야합니다.

```python
def flatten(items, ignore_types=(str, bytes)):
    for x in items:
        if isinstance(x, Iterable) and not isinstance(x, ignore_types):
            for i in flatten(x):
                yield i
        else:
            yield x
```

비록 작은 변화지만 `yield from` 문은 코드를 정리하도록 하고 좋게 만들어 줍니다.

앞에서 언급했듯이 문자열과 바이트를 추가로 검사하는 것은 이런 유형의 개별 문자로 확장을 못하도록 합니다. 만일 원하지 않는 확장의 다른 타입이 있다면 `ignore_types` 인수에 다른 값을 제공할 수 있습니다.

마지막으로 `coroutine`과 `generator` 기반의 동시성을 포함하는 고급 프로그램에서 `yield from`이 더 중요한 규칙을 갖고 있다는 점을 주목하시길 바랍니다. [12.12장]()에 또 다른 예시가 있습니다.

## 4.15. Iterating in Sorted Order Over Merged Sorted Iterables

#### Problem

정렬된 `sequence`의 `collection`을 가지고 있고 서로 병합된 모든 정렬된 `sequence`를 `iterate` 하려고 합니다.

#### Solution

`heapq.merge()` 함수는 정확히 원하는 것을 수행합니다.

```python
import heapq
a = [1, 4, 7, 10]
b = [2, 5, 6, 11]
for c in heapq.merge(a, b):
    print(c)
# 1 2 4 5 6 7 10 11
```

#### Discussion

`heapq.merge`의 `iterative`한 성질은 한 번에 제공된 `sequence`를 절대 읽지 않는다는 것을 의미합니다. 이는 매우 작은 `overhead`와 함께 매우 긴 `sequence`를 사용할 수 있다는 것을 의미합니다. 예를 들어 두 정렬된 파일을 병합하는 방법의 예제입니다.

```python
import heapq

with open('sorted_file_1', 'rt') as file1, \
    open('sorted_file_2' 'rt') as file2, \
    open('merged_file', 'wt') as outf:

    for line in heapq.merge(file1, file2):
        outf.write(line)
```

`heapq.merge()`는 모든 `input sequence`가 이미 정렬되어 있어야 함을 강조하는 것이 중요합니다. 특히 먼저 모든 데이터를 `heap`으로 읽어들이거나 예비로 정렬을 하지 않습니다. 또한 순서의 요구 사항을 충족하는 지 체크하기 위해 `input`의 어떠한 유효성 검사도 수행하지 않습니다. 대신에 각 `input sequence` 앞 쪽으로 부터 항목의 `set`을 확인하고 찾은 가장 작은 항목을 내보냅니다. 선택된 `sequence`로 부터 새 항목을 읽고 모든 `input sequence`가 완전히 소비될 때 까지 프로세스가 반복됩니다.

## 4.16. Replacing Infinite while Loops with an iterator

#### Problem

보통 `iteration` 패턴에 빠지지 않는 어떤 비정상적인 테스트 조건이나 함수를 포함한다고 데이터를 `iteratively`하게 처리하기 위한 `while` 루프를 사용하는 코드가 있습니다.

#### Solution

I/O와 관련된 프로그램에서 다소 일반적인 시나리오는 다음 코드를 작성하기 위해 있습니다.

```python
CHUNKSIZE = 8192

def reader(s):
    while True:
        data = s.recv(CHUNKSIZE)
        if data == b'':
            break
        process_data(data)
```

이 같은 코드는 종종 다음과 같이 `iter()`를 사용하여 대체될 수 있습니다.

```python
# iter(callable, sentinel)
def reader(s):
    for chunk in iter(lambda: s.recv(CHUNKSIZE), b''):
        process_data(data)
```

이런 방식이 약간 회의적이라면 파일과 관련된 비슷한 예로 시도해 볼 수 있습니다.

```python
import sys
f = open('/etc/passwd')
for chunk in iter(lambda: f.read(10), ''):
    n = sys.stdout.write(chunk)
```

#### Discussion

`built-in iter()` 함수의 조금 알려진 기능으로는 선택적으로 0번째 인수로 `callable`을 받고 `sentinel(보초)`(종료되는) 변수를 `input`으로 받습니다. 이 방법이 사용될 때 주어진 `sentinel` 값이 반환될 때 까지 계속 `callable`을 반복적으로 호출하게 되는 `iterator`를 생성합니다.

이 특별한 접근법은 I/O와 관련된 반복적으로 호출되는 특정한 종류의 함수와 함께 잘 동작합니다. 예를 들어 소켓이나 파일에서 데이터를 `chunk`로 읽기를 원할 경우 보통 파일의 끝(EOF)까지 반복적으로 `read()` 또는 `recv()` 호출을 실행해야 합니다. 이 방법은 간단하게 두 기능을 하나의 `iter()` 호출로 결합합니다. 이 Solution에서 `lambda`의 사용은 인수를 취하지 않고 여전히 `recv()` 또는 `read()`에 바라는 크기를 제공하는 `callable` 객체를 만들기 위해 필요한 것입니다.
