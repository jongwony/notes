---
layout: post
title: Python cookbook Chapter 1 한글
tags: ['python','docs', '한글']
progress: 99
---

<div class='warn'>
이 문서는 Python Coobook 3rd edition - O'REILLY, David Beazley & Brian K. jones 를 참고한 것이며 <a href="//wikidocs.net/book/1">Python을 완전히 처음 접하는 경우</a>에는 적합하지 않습니다.<br>개인적으로 공부한 내용이라 오역이 있을 수 있으며 <strong>Memo</strong>에는 실제 C를 이용한 테스트를 하지 않았으므로 이해를 위한 추측성 부분이 많음에 유의하시기 바랍니다.<br>
</div>

Python은 `list`, `set`, `dict`와 같이 유용한 빌트인 자료구조를 다양하게 제공합니다.
대부분의 경우, 이런 구조를 사용하는 것은 간단합니다. 그러나 searching, sorting, ordering, filtering에 관해 일반적인 질문이 자주 일어납니다. 그러므로, 이 챕터의 목표는 데이터에 관련된 일반적인 자료구조와 알고리즘에 대해 다룹니다. 추가로 `collections` 모듈에 포함된 다양한 자료구조에 대한 처리가 제공됩니다.

## 1.1 Sequence를 서로 다른 변수로 unpacking.

#### Problem

N개 요소가 들어있는 `tuple` 또는 `sequence`를 가지고 N개 변수의 집합으로 unpack하고자 합니다.

#### Solution

어떤 `sequence`(또는 iterable 객체)라도 간단한 대입 연산자를 사용하여 변수로 unpack 시킬 수 있습니다. 단지 조건이 변수 및 구조의 수가 `sequence`와 일치한다는 것입니다. 예를 들면

...

만약에 구성요소의 수와 일치하지 않으면 에러가 발생합니다.

```
ValueError: need more than 2 values to unpack 
```

#### Discussion

Unpacking은 `tuple`이나 `list`뿐만 아니라 어떠한 iterable 객체에서도 동작합니다. `string`, `file`, `iterator`, `generator`와 같은 것도 포함합니다. 예를 들면

```python
s = 'Hello'
a, b, c, d, e = s
```

unpacking할 때 가끔 어떤 값을 빼고 싶을 수가 있습니다. Python은 이에 특별한 문법이 없어도, 변수 이름 없이 골라 낼 수 있습니다. 예를 들면

```python
data = [ 'ACME', 50, 91.1, (2012, 12, 21) ]
_, shares, price, _ = data
```

그러나 변수 이름이 다른 용도로 사용되고 있는지는 확인을 해야 합니다.

## 1.2 임의 길이의 iterable 객체로부터 요소를 Unpacking

#### Problem 

iterable 객체로 부터 N개 요소로 unpack할 필요도 있을 것입니다. 그러나 iterable 객체 요소가 N개 이상일 경우에는 "too many values to unpack" 예외가 발생합니다.

#### Solution

python의 "별 표현식(*)"을 사용하여 이 문제를 해결할 수 있습니다. 예를 들어, 전공에서 처음과 마지막 과제의 점수를 빼고 나머지들만 평균을 내려고 합니다. 4가지 과제만 있다면 간단하게 모두 4개로 unpack하면 되지만, 만약 24개 과목이라면? 간단하게 별 표현식으로 쉽게 나타낼 수 있습니다:

```python
def drop_first_last(grades):
    first, *middle, last = grades
    return avg(middle)
```

다른 경우로, 이름과 이메일 주소로 이루어진 유저 정보를 가지고 있고, 그 다음에 휴대폰 번호가 따라온다고 가정합니다. 그러면 다음과 같이 unpack 할 수 있을 것입니다.

```python
user_record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')
name, email, *phone_numbers = user_record
print(phone_numbers)            # [ '773-555-1212', '847-555-1212' ]
```

주목할 만한 점은 휴대폰 번호가 unpack된 수에 관계 없이 (아예 없는 것 포함) `phone_numbers` 변수가 항상 `list`라는 것입니다. 그러므로 어떤 휴대폰 번호를 가진 코드라도 그 코드가 `list`인지 아닌지 또는 추가적으로 어떤 타입인지 검사하는 것에 대해서 고려할 필요는 없습니다.

또한 별표 표시된 변수는 목록에서 처음에 올 수도 있습니다. 예를 들어, 회사의 지난 8분기 매출을 나타내는 값들을 가지고 있다고 가정합니다. 만약 가장 최근 분기와 처음부터 7번째까지의 평균에 대해서 어떤지 보고 싶으면 다음과 같이 할 수 있습니다:

```python
*trailing_qtrs, qurrent_qtr = sales_record
trailing_avg = sum(trailing_qtrs) / len(trailing_qtrs)
return avg_comparison(trailing_avg, current_qtr)
```

#### Memo

별 표현식은 포인터와 비슷하게 보이지만 주소를 전달하는 것이 아니라 실제로는 iterable 객체 내부의 `sequence` 형식을 나타냅니다. Python에서 `sequence`는 객체를 가리키는 것이 아닙니다. `list`, `tuple`, `range` 같은 경우는 `sequence` 타입인 하나의 객체이며 여기서 실제로 `sequence`가 가리키는건 내부의 여러 객체들의 나열이라고 볼 수 있습니다.

예를 들어 `help(range)`를 통한 `range`의 인수는 `range(stop)` 또는 `range(start, stop[, step])` 형식이 필요합니다. 이 인수들에 `range([1, 10, 2])`와 같이 하나의 객체를 쓰게 된다면 `list`를 `integer`로 해석할 수 없다는 타입 에러가 발생합니다. 따라서 별 표현식을 이용하여 iterable 객체를 `integer` 들의 `sequence`로 풀어주는 것입니다. 

```python
a = [1, 10, 2]
# b = *a        # 별 표현식은 (sequence 이므로)객체로 나타낼 수 없습니다.
*b, _ = a       # 별 표현식은 객체가 아니므로 sequence 타입인 tuple을 나타내는 comma를 이용하거나 list로 감싸주어야 합니다.
# b는 [1, 10]인 list이기 때문에 range(start, stop) 형식에 따라 두 integer의 sequence로 나타내어야 합니다.
range(*b)       # range(1, 10, 2) -> 1 3 5 7 9
```

장황하게 썼지만 간단하게 '괄호를 푼다'라고 생각하셔도 무방할 것 같습니다.

#### Discussion

확장된 itarable 객체의 unpacking은 알 수 없거나 임의 길이의 itarable 객체들을 unpacking 하는 데 적합합니다. 자주 이런 iterable 객체들은 그 구조에 몇가지 알려진 구성과 패턴을 가지고 있고(원소 1 다음에 오는 모든 것은 휴대폰 번호 같이), 별 unpacking을 통해 개발자는 itarable 객체에서 관련 요소들을 가져오는 트릭을 쓰는 대신에 이러한 패턴들의 이점을 쉽게 활용할 수 있습니다.

주목할 점은 별 문법이 특히 다양한 길이의 `tuple`들의 `sequence`를 순회할 수 있다는 것입니다. 예를 들어 `tuple`이 추가된 `sequence`를 이런 식으로 나타냅니다.

```python
records = [
    ('foo', 1, 2),
    ('bar', 'hello'),
    ('foo', 3, 4),
]

def do_foo(x, y):
    print('foo', x, y)

def do_bar(s)
    print('bar', s)

for tag, *args in records:
    if tag == 'foo':
        do_foo(*args)
    elif tag == 'bar':
        do_bar(*args)
```

별 unpacking은 또한 splitting 같은 특정한 문자열 처리방식과 함께 사용할 때 유용할 수 있습니다. 예를 들면

```python
line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'
uname, *fields, homedir, sh = line.split(':')
print(uname)                # 'nobody'
print(homedir)              # '/var/empty'
print(sh)                   # '/usr/bin/false'
```

때론 unpack한 값을 버리고 싶을 수 있습니다. unpacking 할 때 * 만으로는 표기할 수 없고, 일반적으로 일회용 변수의 이름을 `_` 또는 `ign`(ignored)와 같이 사용할 수 있습니다. 예를 들면

```python
record = ('ACME', 50, 123.45, (12, 18, 2012))
name, *_, (*_, year) = record
print(year)                 # 2012
```

다양한 함수형 언어에서의 별 unpacking과 `list` 처리 기능 사이에는 서로 유사한 점이 있습니다. 예를 들면 `list`에서 head와 tail요소를 다음과 같이 쉽게 분할할 수 있습니다.

```python
items = [ 1, 10, 7, 4, 5, 9 ]
head, *tail = items
print(head)                 # 1
print(tail)                 # [ 10, 7, 4, 5, 9 ]
```

영리하게 재귀 알고리즘을 수행하기 위해 그런 분할을 수행하는 함수를 작성하는 것을 생각할 수 있습니다. 예를 들면

```python
def sum(items):
    head, *tail = items
    return head + sum(tail) if tail else head

print(sum(items))           # 36
```

그러나 재귀는 [고유한 재귀 제한](//stackoverflow.com/questions/3323001/maximum-recursion-depth)에 의해 실제로 Python의 강력한 기능이 아니라는 점에 주의하셔야 합니다. 그러므로 마지막 예시는 학문적 호기심에 지나지 않습니다.

## 1.3 끝에서 N개 항목 보존하기

#### Problem

순회하거나 일부 다른 종류의 프로세싱 중에 보이는 마지막 몇가지 항목의 제한된 기록을 유지하려고 합니다.

#### Solution

제한된 기록을 유지함으로서 `collections.deque`를 완벽하게 사용하게 됩니다. 예를 들면 다음 코드가 일련의 `sequence`에서 간단한 텍스트 매치를 수행하고 이전 N 줄의 내용과 일치하는 줄을 산출합니다.

```python
from collections import deque

def search(lines, pattern, history=5):
    previous_lines = deque(maxlen=history)
    for line in lines:
        if pattern in line:
            yield line, previous_lines
        previous_lines.append(line)

# Example use on a file
if __name__ == '__main__':
    with open('somefile.txt') as f:
        for line, prevlines in search(f, 'python', 5):
            for pline in pervlines:
                print(pline, end='')
            print(line, end='')
            print('-'*20)
```

#### Memo

`deque` 컬렉션은 제한된 항목을 유지하기에 적합합니다. history를 5로 설정함으로써 큐의 길이가 5로 고정이 되며 이 이상으로 데이터가 들어 올 경우 가장 오래된 항목이 자동으로 삭제됩니다.

제너레이터인 search 함수는 메인 스레드에서 `for`문을 통해 이터레이터를 호출하게 되면서 `yield`문을 한번씩 순회할 때마다 항목이 초기화됩니다. 

`yield`문은 패턴이 해당 라인에 있을 경우 패턴과 `deque`를 넘겨주고 그 다음 항목을 순회할 때마다 이전 라인을 저장합니다. 즉 search 함수에서 패턴이 발견된 라인과 이전 5라인만 넘겨받게 되며 패턴이 발견되지 않으면 5라인만 저장가능한 큐만 이전 줄을 계속 초기화하면서 순환하는 방식입니다.

이전 5줄이 고정되는 만큼 이 내부에서 집약적으로 패턴이 발견된다면 중복 발견되는 패턴들을 모두 호출하기도 합니다.

#### Discussion

항목을 검색하기 위한 코드를 작성할 때는 위에서 보여진 Solution 대로 일반적으로 `yield`문이 포함된 제너레이터 함수를 사용합니다. 이렇게 검색 프로세스가 반환되는 결과를 사용하는 코드로부터 분리됩니다. [제너레이터가 처음입니다.]() 

`deque(maxlen=N)`을 만들어서 고정된 길이의 큐를 사용할 수 있습니다. 새로운 항목이 추가되고 큐가 다 찼을 때는 가장 오래된 항목이 자동으로 제거됩니다. 예를 들면

```python
q = deque(maxlen=3)
q.append(1)
q.append(2)
q.append(3)
print(q)                    # deque([1, 2, 3], maxlen=3)
q.append(4)
q.append(5)
print(q)                    # deque([3, 4, 5], maxlen=3)
```

이런 작업(`append`, `delete`, ...)은 `list`에서 수동으로 수행할 수도 있지만 `queue`를 사용한 방법이 더 우아하고 수행속도도 빠릅니다.

더 일반적으로, `deque`는 간단한 큐 자료구조가 필요할 때마다 사용될 수 있습니다. 최대 길이가 주어지지 않으면, 양쪽 끝에 항목에 대한 `append`와 `pop`을 할 수 있는 무한 큐를 얻게 됩니다. 예를 들면

```python
q = deque()
q.append(1)
q.append(2)
q.append(3)
print(q)                    # deque([1, 2, 3])
q.appendleft(4)
print(q)                    # deque([4, 1, 2, 3])
q.pop()                     # 3
print(q)                    # deque([4, 1, 2])
q.popleft()                 # 4
```

큐의 양 끝에 항목을 추가하고 제거하는 작업은 $$O(1) \ complexity$$ 를 가지게 됩니다. 이는 `list`가 항목에 대한 삽입 삭제를 했을 때 의 $$O(N)$$ 인 `list`와는 다릅니다.

#### Memo

일반적으로 항목의 마지막(worst case)에 접근하기 위해 `list` 자료구조에서는 itaration을 거치는 반면에 
stack과 queue 자료구조를 모두 가지는 `deque`에서는 양 끝쪽이 linked list 구조이므로 이에 $$O(1) \ complexity$$ 로 접근이 가능합니다.

## 1.4 N개 항목에서 최대 최소 찾기

#### Problem

collection의 N개 항목에서 최대 또는 최소를 가진 목록을 만들고 싶습니다.

#### Solution

`heapq` 모듈은 두 함수 - `nlargest()`와 `nsmallest()` - 가 있습니다.

```python
import heapq

nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
print(heapq.nlargest(3, nums))                  # [42, 37, 23]
print(heapq.nsmallest(3, nums))                 # [-4, 1, 2]
```

두 함수 모두 좀 더 복잡한 자료구조와 함께 사용할 수 있는 key parameter도 제공됩니다. 예를 들면

```python
portfolio = [
    {'name': 'IBM', 'shares': 100, 'price': 91.1},
    {'name': 'AAPL', 'shares': 50, 'price': 543.22},
    {'name': 'FB', 'shares': 200, 'price': 21.09},
    {'name': 'HPQ', 'shares': 35, 'price': 31.75},
    {'name': 'YHOO', 'shares': 45, 'price': 16.35},
    {'name': 'ACME', 'shares': 75, 'price': 115.65}
]

cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])
expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])
```

#### Discussion

만약 N개의 최소 또는 최대 항목을 찾고 N이 `collection`의 전체 길이보다 작은 경우에 이 함수들이 우수한 성능을 제공합니다. 아래는 먼저 `heap` 순서로 정렬된 `list` 데이터를 바꾸는 예제입니다.

```python
nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
import heapq
heap = list(nums)
heapq.heapify(heap)
print(heap)                 # [-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8]
```

`heap`의 가장 중요한 특징은 `heap[0]`이 항상 최소 항목이라는 것입니다. 게다가, 처음 항목을 빼내고 그 다음 최소 항목으로 바꾸는 `heapq.heappop()` 메서드를 사용해서 다음 최소 항목을 쉽게 찾을 수 있습니다. (이 작업은 `heap` 크기가 N일 때 $$O(\log N)$$ 만큼 필요하게 됩니다.) 예를 들어 가장 작은 세 항목은 이렇게 찾으면 됩니다.

```python
heapq.heappop(heap)
heapq.heappop(heap)
heapq.heappop(heap)
```

`nlargest()`와 `nsmallest()`함수는 상대적으로 적은 수의 항목을 찾을 경우에 가장 적절합니다. 길이가 1인 최대 최소를 찾고자 할때는 `min()`과 `max()`를 사용하는 것이 빠릅니다. 유사하게, N이 `collection` 자체와 거의 같은 크기라면, 보통 `sorted(items)[:N]`이나 `sorted(items)[-N:]`처럼 먼저 정렬하고 `slice`를 하는게 빠릅니다. `nlargest()`와 `nsmallest()`의 실제 구현은 어떻게 돌아가는지 알고 이러한 최적화 중 일부를 수행한다는 점에 유의해야 합니다.(앞서 N이 입력과 같은 크기에 가깝다면 정렬을 사용합니다.)  

꼭 이런 방식을 사용할 필요는 없지만, `heap`의 구현은 흥미롭고 가치있는 연구 주제입니다. 이는 보통 알고리즘이나 자료구조에 대한 적절한 책에서 찾을 수 있습니다. `heapq` 모듈에 대한 문서는 관련 구현 세부 사항에서 다룹니다.

## 1.5 Priority Queue 구현

#### Problem

주어진 우선순위에 따라 항목을 정렬하고 각 `pop` 작업을 통해 항상 가장 높은 우선순위를 가진 항목을 반환하는 큐를 구현하려고 합니다.

#### Solution

다음 클래스는 간단한 우선순위 큐를 구현하기 위해 `heapq` 모듈을 사용한 것입니다.

```python
import heapq

class PriorityQueue:

    def __init__(self):
        self._queue = []
        self._index = 0

    def push(self, item, priority):
        heapq.heappush(self._queue, (-priority, self._index, item))
        self._index += 1

    def pop(self):
        return heapq.heappop(self._queue)[-1])
```

사용 방법에 대한 예제는 다음과 같습니다.

```python
class Item:

    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return 'Item({!r})'.format(self.name)

q = PriorityQueue()
q.push(Item('foo'), 1)
q.push(Item('bar'), 5)
q.push(Item('spam'), 4)
q.push(Item('grok'), 1)
q.pop()                     # Item('bar')
q.pop()                     # Item('spam')
q.pop()                     # Item('foo')
q.pop()                     # Item('grok')
```

첫 번째 `pop()` 작업이 가장 높은 우선순위를 가진 항목을 반환하는 방법과 두 항목(`foo`, `grok`)이 같은 우선순위를 가질 때 먼저 큐에 들어간 순서와 동일하게 반환 된다는 점이 주목됩니다. 

#### Discussion

이 방법의 핵심은 `heapq` 모듈의 사용에 관한 것입니다. `heapq.heappush()`와 `heapq.heappop()` 함수는 첫 번째 항목이 가장 작은 우선순위를 갖도록 하는 `_queue` 리스트로부터 항목을 삽입하고 삭제합니다.
`heappop()` 메서드는 항상 "가장 작은" 항목을 반환하기 때문에, 그것이 정확한 항목을 큐에서 `pop` 할 수 있게 만드는 열쇠입니다. 게다가, `push`와 `pop` 작업이 N개의 항목이 있는 heap에선 $$O(\log N) \ complexity$$ 를 가지기 때문에 N이 아주 큰 값 이더라도 상당히 효율적입니다.

이 방법에서는 큐가 `(-priority, index, item)` 형태의 `tuple`로 이루어집니다. `priority` 값은 가장 높은 우선 순위에서 가장 낮은 우선 순위까지 항목을을 정렬한 큐를 얻기 위해 음수를 취합니다. 이는 일반 heap 순서의 가장 낮은 우선 순위부터 가장 높은 우선 순위까지 정렬되는 것과는 반대입니다.

`index` 변수의 역할은 같은 우선순위를 가진 항목을 적절히 정렬하기 위함입니다. 계속 증가하는 index를 유지함으로써, 항목이 삽입되는 순서에 따라 정렬될 것입니다. 그러나 index가 또한 같은 우선 순위 레벨을 가진 항목을 비교하는 데 중요한 역할을 수행할 수도 있습니다.

정교하게 설명하자면, 예제의 `Item` 인스턴스만으로는 정렬될 수 없습니다.

```python
a = Item('foo')
b = Item('bar')
a < b                   # unorderable types error
```

추가 index와 `(priority, index, item)` `tuple`을 도입함으로써, 두 `tuple`이 `index`에 대해 동일한 값을 가질 수 없으므로 이 문제를 완전히 피할 수 있게 됩니다.(Python은 한번 비교 결과를 결정 할 수 있으면 나머지 `tuple`값은 절대 신경쓰지 않습니다.)

```python
a = (1, 0, Item('foo'))
b = (5, 1, Item('bar'))
c = (1, 2, Item('grok'))
a < b                   # True
a < c                   # True
```

만약 큐를 스레드간 통신에 이용하고 싶다면, 적절한 `lock`과 `signal`을 추가해야 합니다. 12.3에 이 방법의 예제가 있습니다.

`heapq` 모듈에 대한 문서를 참조하시면 힙의 이론과 구현에 대한 토론과 추가적인 예제가 있습니다.

## 1.6 Dictionary에서 key를 여러 값들로 매핑

#### Problem

key를 하나이상의 값들로 매핑하는 `dictionary`를 만들 경우("`multidict`라고 불림")

#### Solution

`dictionary`는 각 key들을 하나의 값들로 매핑합니다. 만약 key를 여러 값들로 매핑할 경우 `list`나 `set`같은 또 다른 컨테이너에 여러 값들을 저장해야 합니다. 예를 들어

```python
d = {
    'a' : [1, 2, 3],
    'b' : [4, 5]
}

e = {
    'a' : {1, 2, 3},
    'b' : {4, 5}
}
```

`list`나 `set`을 사용할 지 여부는 용도에 따라 다릅니다. 삽입된 항목의 순서를 보존하고 싶다면 `list`를 사용하고 중복을 제거하고 싶다면 `set`(순서도 신경쓰고 싶지 않다면)을 사용하시면 됩니다.

`dictionary`를 쉽게 생성하기 위해 `collection` 모듈의 `defaultdict`를 사용할 수 있습니다.
`defaultdict`의 기능은 자동으로 처음 값을 초기화하기 때문에 간단하게 항목을 추가하는데 집중할 수 있습니다.

```python
from collections import defaultdict

d = defaultdict(list)
d['a'].append(1)
d['a'].append(2)
d['b'].append(4)
...

d = defaultdict(set)
d['a'].add(1)
d['a'].add(2)
d['b'].add(4)
...
```

한가지 주의할 점은 `defaultdict`가 나중에 액세스 되는 키에 대한 `dictionary` 항목을 자동으로 작성한다는 것입니다.(심지어 현재 `dictionary`에 발견되지 않아도 작성합니다.) 이를 원하지 않으면 일반 `dict`에 `setdefault()`를 사용하는 방법이 있습니다.  예를 들면

```python
d = {}      # dict()
d.setdefault('a', []).append(1)
d.setdefault('a', []).append(2)
d.setdefault('b', []).append(4)
```

하지만 많은 프로그래머들이 `setdefault()`를 약간 부자연스럽다고 생각합니다. 위처럼 각각의 호출에서 항상 초기값의 새로운 인스턴스를 생성한다는 사실은 말할 것도 없습니다.

#### Discussion

원칙적으로, 다중 값 사전을 만드는 것은 간단합니다. 하지만 첫번째 값의 초기화를 일일이 수행하려고 하면 지저분해 질 수 있습니다. 다음과 같은 코드가 있을 수 있습니다.

```python
d = {}
for key, value in pairs:
    if key not in d:
        d[key] = []
    d[key].append(value)
```

`defaultdict`를 사용하여 좀더 깔끔한 코드를 간단히 이끌어낼 수 있습니다.

```python
d = defaultdict(list)
    for key, value in pairs:
        d[key].append(value)
```

## 1.7 Dictionary 순서를 보존하기

#### Problem

`dictionary`를 만들고 itarating 또는 serializing 할 때 항목의 순서를 제어하고 싶습니다.

#### Solution

`dictionary`에서 항목의 순서를 제어하기 위해서는 `OrderedDict`라는 `collection`모듈을 사용할 수 있습니다. 이는 iterating 할 때 데이터의 본래 삽입한 순서를 정확하게 보존합니다.

```python
from collections import OrderedDict

d = OrderedDict()
d['foo'] = 1
d['bar'] = 2
d['spam'] = 3
d['grok'] = 4

for key in d:
    print(key, d[key])

for key, value in d.items():
    print(key, value)
```

`OrderedDict`는 나중에 서로 다른 형식으로 serialize 또는 encode 하고 싶은 매핑을 만들 때 특히 유용합니다. 예를 들어 JSON 인코딩에 나타나는 필드의 순서를 정밀하게 제어하려면 먼저 `OrderedDict`에서 데이터를 만드는 것이 트릭이 될 것입니다.

```
import json
json.dumps(d)           # ordered dictionary
```

#### Discussion

`OrderedDict`는 내부적으로 삽입 순서에 따른 키를 정렬하는 `doubly linked list` 형식을 유지합니다.
처음 새 항목이 삽입되면, 이 목록의 가장 마지막쪽으로 들어갑니다. 이미 존재하는 기본키가 변경된 후는 순서를 변경하지 않습니다.

`OrderedDict`의 길이는 추가적인 `linked list`가 생성되기 때문에 일반 `dictionary` 크기의 두배 이상임에 유의하셔야 합니다. 그러므로 많은 수의 `OrderedDict` 인스턴스를 포함하는 데이터 구조를 만들 경우(10만 줄의 CSV 파일을 읽어 `OrderedDict` 인스턴스의 리스트로 만든다던지...) `OrderedDict` 사용으로 인한 이점이 메모리 오버헤드를 넘는지 판단하기 위해 자신의 애플리케이션 요구사항을 연구해야 합니다.

## 1.8 Dictionary 계산

#### Problem

최소나 최대를 구하거나 정렬 하는 등 다양한 계산을 `dictionary`에서 수행하려고 합니다.

#### Solution

주식이름을 가격에 매핑하는 `dictionary`를 고려해 봅니다.

```python
prices = {
    'ACME': 45.23,
    'AAPL': 612.78,
    'IBM': 205.55,
    'HPQ': 37.20,
    'FB': 10.75
}
```

`dictionary`내용에서 유용한 계산을 수행하려면, 종종 key와 value를 `zip()`을 이용하여 반전시키는 것이 유용할 때가 있습니다. 이렇게 가격의 최대 최소를 가진 주식 이름을 찾을 수 있게 됩니다.

```python
min_price = min(zip(prices.values(), prices.keys()))
max_price = max(zip(prices.values(), prices.keys()))
```

비슷하게, `zip()`과 `sorted()`를 함께 사용해서 데이터의 순위를 정할 수 있습니다.

```python
prices_sorted = sorted(zip(prices.values(), prices.keys()))
```

이런 계산을 수행할 때는 `zip()`이 `iterator`를 한번만 생성하는 것에 유의하셔야 합니다.

```python
prices_and_names = zip(prices.values(), prices.keys())
print(min(prices_and_names))    # OK
print(max(prices_and_names))    # ValueError: max() arg is an empty sequence
```

#### Memo

이 문서는 python 3 버전으로, 문맥으로 보아 `zip()` 함수는 `tuple`이 아니라 `iterator`를 반환 함을 알 수 있습니다.
`for`문을 통해 `iterator`를 단 한번 호출하게 되는데 이를 변수에 할당해버리면 다음에 다시 이를 참조했을 때 `next`함수가 `StopIteration`까지 순회한 상태이기 때문에 `None` 객체를 반환하는 것입니다.

그러므로 변수에 `zip()`함수를 할당하는 것 보다는 그냥 일일이 `zip()`함수를 쓰는 것을 권장하는 것 같습니다.
`tuple`을 이용하려면 `tuple(zip())`을 통해 해당 컨테이너에 다시 넣거나, `itertools.izip` 모듈을 이용하면 됩니다. [참고](//stackoverflow.com/questions/1663807/how-can-i-iterate-through-two-lists-in-parallel-in-python?answertab=votes#tab-top)

#### Discussion

만약 일반적으로 데이터 축소를 `dictionary`에서 수행하려면 key 처리 만으로 찾아낼 것입니다.

```python
min(prices)                 # 'AAPL'
max(prices)                 # 'IBM'
```

하지만 사실 value에 대한 계산을 수행하려고 할 것이기 때문에 원하는 결과가 아닐 수 있습니다.
`dictionary`의 `values()` 메서드를 통해 이를 해결 할 수 있습니다.

```python
min(prices.values())        # 10.75
max(prices.values())        # 612.78
```
가끔 불행히도 이는 원하는 것과 정확히 일치하지는 않습니다. 예를 들어, 해당하는 키에 대한 정보를 알고자 하는 경우가 있습니다. (어떤 주식이 가장 낮은 가격인가와 같이)

최대 최소에 해당하는 key를 `min()`과 `max()` 함수가 제공하는 key를 통해 얻을 수 있습니다.

```python
min(prices, key=lambda k: prices[k])    # 'FB'
max(prices, key=lambda k: prices[k])    # 'AAPL'
```

하지만 최소를 얻으려면 추가적인 조회 단계를 수행해야 할 것입니다.

```python
min_value = prices[min(prices, key=lambda k: prices[k])]
```

`zip()`과 관련된 해결책은 `dictionary`를 `(value, key)` 쌍으로 반전함으로써 문제를 해결했습니다.
어떤 `tuple`에 대해서 비교를 수행할 때는 `value` 요소가 처음 비교되고 그 다음에 `key`를 비교합니다. 이렇게 함으로써 원하는 동작을 정확하게 제공할 수 있으며 단일 명령을 사용하여 `dictionary` 내용을 수행함에 있어서 좀 더 쉽게 축소나 정렬을 가능하게 할 수 있습니다. 

`(value, key)`쌍과 관련된 계산에서 key는 여러 항목이 동일한 값을 갖는 인스턴스에 대해 결과를 결정하는 데에 사용될 수 있다는 점에 유의해야 합니다. 계산에서의 `min()`과 `max()`같이, 최소 또는 최대 키 값을 가진 항목은 중복 값으로 반환될 수 있습니다.

```python
prices = { 'AAA' : 45.23, 'ZZZ' : 45.23 }
min(zip(prices.values(), prices.keys()))        # (45.23, 'AAA')
max(zip(prices.values(), prices.keys()))        # (45.23, 'ZZZ')
```

## 1.9 두 Dictionary의 공통점 찾기

#### Problem

두 `dictionary`에서 같은 key와 같은 value 등의 공통적인 부분을 찾아야 합니다.

#### Solution

두 `dictionary`가 다음과 같이 주어지면

```python
a = {
    'x' : 1,
    'y' : 2,
    'z' : 3
}

b = {
    'w' : 10,
    'x' : 11,
    'y' : 2
}
```

두 `dictionary`가 공통점이 있는 것을 알아내기 위해 `keys()` 또는 `items()` 메서드로 일반적인 `set` 연산으로 간단하게 수행할 수 있습니다.

```python
# Find keys in common
a.keys() & b.keys()         # { 'x', 'y' }

# Find keys in a that are not in b
a.keys() - b.keys()         # { 'z' }

# Find (key, value) pair in common
a.items() & b.items()       # { ('y', 2) }
```

이런 종류의 연산은 `dictionary` 내용을 조작하거나 필터링하는데 사용될 수도 있습니다. 예를 들면, 선택한 키를 제거한 새로운 `dictionary`를 만든다면 여기 `dictionary comprehension`을 이용하여 만든 샘플 코드가 있습니다.

```python
# Make a new dictionary with certain keys removed
c = { key:a[key] for key in a.keys() - {'z', 'w'}}      # {'x': 1, 'y': 2}
```

`keys()` 메서드는 key가 노출되는 `keys-view` 객체를 반환합니다. `keys-view`의 조금 알려진 기능으로는 집합의 합집합, 교집합, 차집합 연산을 일반적으로 지원한다는 것입니다. 그러므로 `dictionary`에서 일반적인 `set` 연산을 수행해야 한다면, `keys-view` 객체를 먼저 `set`으로 바꾸는 작업 없이도 직접 사용이 가능하다는 것입니다.

`items()` 메서드는 `(key, value)`쌍으로 이루어진 `items-view` 객체를 반환합니다. 이 객체 역시 `set` 연산을 지원하고 두 `dictionary`에서 공통적인 `(key, value)` 쌍을 찾는 연산을 수행하는 데 사용할 수 있습니다.

비슷하지만 `values()` 메서드는 위에서 설명된 이런 집합 연산을 지원하지 않습니다. 부분적으로 이는 key와는 달리 항목에서 고유하게 보장되지 않는 value가 포함되기 때문입니다. 이것만으로도 논란이 되는 `set` 연산을 만들어 낼 수 있습니다. 하지만 계산을 꼭 수행해야 한다면 간단하게 `value`를 `set`으로 먼저 변환하는 방법을 사용할 것입니다.

## 1.10 Sequence의 순서를 유지하면서 중복을 제거

#### Problem

`sequence`에서 중복 값들을 제거하지만 항목의 순서는 유지하고 싶습니다.

#### Solution

`sequence`의 값들이 `hashable` 하면, 이 문제는 `set`과 `generator`를 사용하여 쉽게 풀 수 있습니다.

```python
def dedupe(items):
    seen = set()
    for item in items:
        if item not in seen:
            yield item
            seen.add(item)
```

이 함수를 다음과 같이 사용할 수 있습니다.

```python
a = [1, 5, 2, 1, 9, 1, 5, 10]
list(dedupe(a))         # [1, 5, 2, 9, 10]
```

`sequence`가 `hashable`인 경우에만 가능합니다. `dict`같은 `unhashable`타입 `sequence`의 중복을 제거하려면 다음과 같이 예제를 조금 변경할 수 있습니다.

```python
def dedupe(items, key=None):
    seen = set()
    for item in items:
        val = item if key is None else key(item)
        if val not in seen:
            yield item
            seen.add(val)
```

`key` 인수의 목적은 `sequence` 항목을 중복찾기가 목적인 `hashable` 타입으로 변환하는 함수를 지정하기 위한 것입니다.

```python
a = [ {'x':1, 'y':2}, {'x':1, 'y':3}, {'x':1, 'y':2}, {'x':2, 'y':4}]
list(dedupe(a, key=lambda d: (d['x'],d['y'])))
list(dedupe(a, key=lambda d: d['x'])) 
```

이 solution 또한 단일 필드의 값이나 속성 또는 더 큰 자료구조의 값을 기반으로 중복을 제거하려는 경우에도 잘 작동합니다.

#### Discussion

중복을 제거하기만 하려면 `set`으로 만드는게 쉽습니다.

하지만 이런 접근은 어떤 종류의 순서도 유지하지 않습니다. 그 결과 데이터가 나중에 훼손됩니다. 위의 solution은 이를 피하는걸 보여줍니다.

`generator`함수를 사용함으로써 `list` 프로세싱에 직접 연결될 필요 없이 매우 일반적인 목적의 함수가 되길 원하는 사실을 반영합니다. 예를 들어 중복되는 라인을 제거하면서 파일을 읽으려면 간단히 이렇게 하면 됩니다.

```python
with open(somefile, 'r') as f:
    for line in dedupe(f):
        ...
```

`key` 함수의 지정으로 `sorted()`, `min()`, `max()`와 같은 `built-in` 함수에서 유사한 기능을 모방하게 됩니다. [1.8, 1.13 참조]

## 1.11 Slice 이름 지정

#### Problem

프로그램이 하드코딩한 `slice` 지수들 덩어리로 읽기가 힘들어져서 정리를 하고 싶습니다.

#### Solution

고정된 필드를 가진 레코드 문자열에서 특정 데이터 필드를 가져오는 코드가 있다고 가정합니다.

```python
###### # #0123456789012345678901234567890123456789012345678901234567890'
record = '....................100          .......513.25     ..........'
cost = int(record[20:32]) * float(record[40:48])
```
이 대신에 이런 이름을 지으면 어떨까요?

```python
SHARES = slice(20,32)
PRICE = slice(40,48)

cost = int(record[SHARES]) * float(record[PRICE])
```

이런 버전이 하드코딩 인덱스를 많이 필요하지 않게 되고 무엇을 하려고 하는지 훨씬 명확해집니다.

#### Discussion

일반적으로 하드코딩된 인덱스 값이 많은 코드를 작성하면 가독성과 유지보수가 엉망이 됩니다. 예를 들어, 1년 후 이 코드를 다시 봤을 때 자신이 쓴 코드에 대해 한참 보고 생각하게 될 것입니다. solution은 단순히 좀더 명확하게 코드가 무엇을 수행하는지 보여주는 방법입니다.

일반적으로, `slice()` `built-in` 함수는 슬라이스가 허용되는 모든 곳에서 사용 가능한 슬라이스 객체를 만들어 줍니다.

```python
items = [0, 1, 2, 3, 4, 5, 6] 
a = slice(2, 4)
print(items[2:4])          # [2, 3]
print(items[a])            # [2, 3]
items[a] = [10,11]
print(items)               # [0, 1, 10, 11, 4, 5, 6]
del items[a]
print(item)                # [0, 1, 4, 5, 6]
```

`slice` 인스턴스 `s`의 `s.start`, `s.stop`, `s.step` 속성을 살펴봄으로써 좀더 많은 정보를 얻을 수 있습니다.

```python
a = slice(10, 50, 2)
print(a.start)             # 10
print(a.stop)              # 50
print(a.step)              # 2
```

추가로, `indices(size)` 메서드를 사용해서 `sequence`의 특정 길이를 슬라이스하는 맵을 만들 수 있습니다. 이는 indexing 할 때 `IndexError` 예외를 피하는 방법 같이 모든 값이 경계안에 적합하도록 적절히 제한된 `(start, stop, step)` `tuple`을 반환합니다.

```python
s = 'HelloWorld'
a.indices(len(s))           # (5, 10, 2)
for i in range(*a.indices(len(s))):
    print(s[i])             # W r d
```

#### Memo

예시가 잘못 된 것 같습니다. 실제로 `a.indices(len(s))`는 위에서 쓴 `a = slice(10, 50, 2)`를 그대로 사용할 경우 `(10, 10, 2)`을 반환합니다. indices 메서드가 구체적으로 어떻게 구현되어 있는지는 잘 모르지만 간단한 테스트를 통해 원리를 이해하실 수는 있을 겁니다.

```python
a = slice(10, 50, 2)
for i in range(100):
    print(a.indices(i))
```

실제로 `a = (5, 50, 2)`일 경우에는 제대로 동작합니다.

## 1.12 Sequence의 가장 빈번하게 일어나는 항목을 확인하기

#### Problem

항목의 `sequence`(iterable 객체에서의 sequence)에서 가장 빈번하게 발생하는 `sequence`의 항목(sequence 내부의 객체)을 확인하고 싶습니다.

#### Solution

`collections.Counter` 클래스는 이 문제를 해결할 수 있게 설계되었습니다. 심지어 편리한 `most_common()` 메서드가 함께 제공됩니다. 예를 들어, 단어목록이 있고 가장 자주 나오는 단어를 찾고 싶다고 하면

```python
words = [
    'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes', 'the',
    'eyes',' the', 'eyes', 'the', 'eyes', 'not', 'around', 'the', 'eyes', 
    "don't", 'look', 'around', 'the', 'eyes', 'look', 'into', 'my', 'eyes',
    "you're", 'under'    
]

from collections import Counter
word_counts = Counter(words)
top_three = word_counts.most_common(3)
print(top_three)    # [('eyes', 8), ('the', 5), ('look', 4)]
```

#### Discussion

`Counter` 객체는 `hashable`한 입력 항목의 모든 `sequence`를 받을 수 있습니다. 아래에 `Counter`가 항목을 발생횟수에 매핑하는 `dictionary`라는 예제를 보여줍니다.

```python
word_counts['not']      # 1
word_counts['eyes']     # 8
```

만약 수동으로 횟수를 증가시키려면 간단하게 덧셈 연산자를 사용합니다.

```python
morewords = ['why', 'are', 'you', 'not', 'looking', 'in', 'my', 'eyes']
for word in morewords:
    word_counts[word] += 1
word_counts['eyes']     # 9
```

또는 `update()` 메서드를 사용할 수도 있습니다.

```python
word_counts.update(morewords)
```

`Counter` 인스턴스의 조금 알려진 기능으로는 다양한 수학적인 연산자를 쉽게 결합 할 수 있다는 것입니다.

```python
a = Counter(words)
b = Counter(morewords)
# Combine counts
c = a + b
# Subtract counts
d = a - b
```

말할 필요도 없이 `Counter`객체는 데이터를 도표화하고 셀 필요가 있는 거의 모든 종류의 문제에 대단히 유용한 도구입니다. `dictionary`가 포함된 수동적으로 일일이 기록한 solution보다 이 방법을 선호하는 것이 좋습니다.

## 1.13 Dictionary들의 List를 어떤 키에 대해 정렬하기

#### Problem 

`dictionary`의 `list`에서 하나 이상의 `dictionary value`에 따라 항목을 정렬하려고 합니다.

#### Solution

`operator` 모듈의 `itemgetter` 함수를 사용함으로써 구조의 타입을 쉽게 정렬할 수 있습니다.
만약 웹사이트에서 회원들의 리스트를 얻기 위해 데이터베이스 테이블을 쿼리한다고 가정하면 다음과 같은 데이터 구조를 받게 될 것입니다.

```python
rows = [
    {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},
    {'fname': 'David', 'lname': 'Beazley', 'uid': 1002},
    {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},
    {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}
]
```

모든 `dictionary`에 대해 공통의 어떤 필드로 정렬된 이러한 행을 출력하는 것은 상당히 쉽습니다.

```python
from operator import itemgetter
rows_by_fname = sorted(rows, key=itemgetter('fname'))
rows_by_uid = sorted(rows, key=itemgetter('uid'))
print(rows_by_fname)
print(rows_by_uid)
```

`itemgetter()` 함수는 복합적인 키도 사용 가능합니다.

```python
rows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))
print(rows_by_lfname)
```

#### Discussion

이 예제에서는 `rows`가 `key`를 인자로 하는 `sorted()` `built-in` 함수를 거칩니다. 이 인자는 `rows`로 부터 입력 받아 정렬의 기준으로 사용할 수 있는 값을 리턴하는 단일 항목을 허용하는 `callable`한 함수여야 합니다.
`itemgetter()` 함수는 그러한 `callable` 함수를 만듭니다.

`operator.itemgetter()` 함수는 `rows` 레코드에서 원하는 값을 추출하는데 사용되는 조회 인덱스를 인수로 갖습니다. 이는 `dictionary key` 이름이나 수치 또는 객체의 `__getitem__()` 메서드로부터 넘겨받은 값이 될 수 있습니다. `itemgetter()`에 여러 인덱스를 넘겨 줄 경우, 그것이 생성하는 `callable` 함수는 그안의 모든 원소들을 가진 `tuple`을 반환하고 `sorted()` 함수는 `tuple`의 순서로 정렬한 것에 따라 출력이 정렬될 것입니다. 이는 (성, 이름이나, 위의 예시와 같이)동시에 여러 필드를 정렬해야 할 때 유용할 수 있습니다.

`itemgetter()`의 기능은 `lambda` 표현식으로 대체되기도 합니다.

```python
rows_by_fname = sorted(rows, key=lambda r: r['fname'])
rows_by_lfname = sorted(rows, key=lambda r: (r['lname'], r['fname']))
```

이 방법이 좋은 경우도 있습니다. 하지만 `itemgetter()` 를 포함한 방법이일반적으로 좀 더 빠르게 실행됩니다. 그러므로 성능이 중요하게 고려된다면 선호되는 방법입니다.

마지막으로, 하지만 적어도 위의 예시에 이런 기술을 `min()`과 `max()`와 같은 함수에 적용할 수 있다는 것을 잊지 않았으면 좋겠습니다.

```python
min(rows, key=itemgetter('uid')) # {'fname': 'John', 'lname': 'Cleese', 'uid': 1001} 
max(rows, key=itemgetter('uid')) # {'fname': 'Big', 'lname': 'Jones', 'uid': 1004} 
```

#### Memo

실제로 `itemgetter()`와 `lambda` 표현식 간의 속도를 측정해 보았습니다.

```python
from timeit import timeit
from operator import itemgetter
from random import randint

a = list()
for _ in range(10):
    d = dict()
    for i in range(5):
        d[i] = randint(0, 10)
    a.append(d)

print(a)

def f1():
    sorted(a, key=lambda x: x[1])

def f2():
    sorted(a, key=itemgetter(1))

print(timeit(f1))       # 3.597947261030393
print(timeit(f2))       # 2.887598172241222
```

추측이지만 `lambda` 표현식은 Python의 표현식이고 `itemgetter()` 함수는 C언어 레벨로 호출되어 차이가 나는 것 같습니다. [참고](//stackoverflow.com/questions/11287207/why-should-i-use-operator-itemgetterx-instead-of-x)

## 1.14 Native Comparison 없이 객체를 정렬

#### Problem

비교 연산을 사용하지 않고 같은 클래스의 객체를 정렬하고 싶습니다.

#### Solution

`sorted()` `built-in` 함수는 `sorted`가 객체를 비교하는 데 사용할 객체의 일부 값을 반환하는 `callable` 객체를 전달 할 수 있는 `key` 인수를 사용합니다. 만약 `User` 인스턴스의 `sequence`를 사용하고, 그 `user_id` 속성으로 정렬하고 싶으면 `User` 인스턴스에 `user_id`를 반환하도록 `callable` 객체를 제공하면 됩니다.

```python
class User:
    
    def __init__(self, user_id):
        self.user_id = user_id

    def __repr__(self):
        return 'User({})'.format(self.user_id)

users = [User(23), User(3), User(99)]
print(users)                                    # [User(23), User(3), User(99)]
print(sorted(users, key=lambda u: u.user_id))   # [User(3), User(23), User(99)]
```

`dictionary`에서의 `key`와 비슷하게 객체에서는 `lambda`를 사용하는 대신에 `operator.attrgetter()`를 사용할 수 있습니다.

```python
from operator import attrgetter
print(sorted(users, key=attrgetter('user_id'))  # [User(3), User(23), User(99)]
```

#### Discussion

`lambda` 또는 `attrgetter()`를 사용할 지에 대해서는 개인적인 취향일 수 있습니다. 하지만 마찬가지로 `attrgetter()`가 보통 더 빠르고 심지어 동시에 여러 필드를 추출할 수 있는 부가적인 기능도 가지고 있습니다. 이는 `dictionary`에서 `operator.itemgetter()`를 사용한 것과 유사합니다. 예를 들어 `User` 인스턴스가 `first_name`과 `last_name` 속성을 가지고 있다면 이렇게 수행할 수 있습니다.

```python
by_name = sorted(users, key=attrgetter('last_name', 'first_name'))
```

마찬가지로 이 예제에 사용된 기술은 `min()` 및 `max()` 와 같은 함수에 적용될 수 있습니다.

```python
min(users, key=attrgetter('user_id'))       # User(3)
max(users, key=attrgetter('user_id'))       # User(99)
```

## 1.15 Grouping Records Together Based on a Field

#### Problem

`dictionary`나 인스턴스의 `sequence`에서 `date`같이 특정 필드 값을 바탕으로 한 그룹의 데이터를 순회시키고 싶습니다.

#### Solution

`itertools.groupby()` 함수는 데이터를 묶는데 특히 유용합니다. 예를 들어 `dictionary`의 `list`를 다음과 같이 가지고 있다고 하면

```python
rows = [
    {'address': '5412 N CLARK', 'date': '07/01/2012'},
    {'address': '5148 N CLARK', 'date': '07/04/2012'},    
    {'address': '5800 E 58TH', 'date': '07/02/2012'},    
    {'address': '2122 N CLARK', 'date': '07/03/2012'},    
    {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'},    
    {'address': '1060 W ADDISON', 'date': '07/02/2012'},    
    {'address': '4801 N BROADWAY', 'date': '07/01/2012'},    
    {'address': '1039 W GRANVILLE', 'date': '07/04/2012'}, 
]
```

이제 날짜를 그룹으로 나눈 데이터를 순회하려고 합니다. 이를 위해 먼저 원하는 (여기선 날짜)필드로 정렬해야 하고 `itertools.groupby()`를 사용합니다.

```python
from operator import itemgetter
from itertools import groupby

# Sort by the disired field first
rows.sort(key=itemgetter('date'))

# Iterate in groups
for date, items in groupby(rows, key=itemgetter('date')):
    print(date)
    for i in items:
        print('\t', i)
```

다음과 같은 결과가 출력됩니다.

```
07/01/2012
     {'address': '5412 N CLARK', 'date': '07/01/2012'}
     {'address': '4801 N BROADWAY', 'date': '07/01/2012'}
07/02/2012
     {'address': '5800 E 58TH', 'date': '07/02/2012'}
     {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'}
     {'address': '1060 W ADDISON', 'date': '07/02/2012'}
07/03/2012
     {'address': '2122 N CLARK', 'date': '07/03/2012'}
07/04/2012
     {'address': '5148 N CLARK', 'date': '07/04/2012'}
     {'address': '1039 W GRANVILLE', 'date': '07/04/2012'}
```

#### Discussion

`groupby()` 함수는 `sequence`를 스캔하고 동일한 값(또는 주어진 `key`함수에서 리턴된 값)의 순차적인 "실행"을 찾음으로써 작동합니다. 각 순회 과정에서 같은 값의 그룹에 속한 모든 항목에서 만들어지는 `iterator`와 함께 값을 리턴합니다.

관심있는 필드에 따라 데이터를 정렬하는 예비과정이 중요합니다. `groupby()`가 연속된 항목만 검사하기 때문에 먼저 정렬에 실패하면 원하는 대로 레코드를 그룹화 할 수 없습니다.

만약 간단히 랜덤 액세스가 허용되는 대용량 데이터 구조에서 데이터를 날짜로 그룹화 하고 싶으면 `defaultdict()`를 사용하여 `multidict`를 만드는 게 낫습니다. 이는 1.6장에 소개되어 있습니다.

```python
from collection import defaultdict

rows_by_date = defaultdict(list)
for row in rows:
    rows_by_date[row['date']].append(row)
```

이렇게 하면 다음과 같이 각 날짜의 레코드에 쉽게 액세스 할 수 있습니다.

```python
for r in rows_by_date['07/01/2012']:
    print(r)
```

후자의 경우에, 레코드를 먼저 정렬할 필요가 없습니다. 그러므로 메모리가 문제가 되지 않는다면 이 방법이 먼저 레코드를 정렬하고 `groupby()`를 사용하여 순회하는 것 보다 빠를 수 있습니다.

#### Memo

문맥으로 보아 `groupby()` 함수는 데이터베이스에서 지원하는 `SQL`의 `GROUP BY`절과 대응됩니다. `SQL`의 `GROUP BY`절 역시 암묵적으로 정렬이 수행됩니다.

실제 대용량 데이터베이스 운영 환경의 아키텍처나 `GROUP BY`절이 수행하는 정렬도 고려해야 하겠지만 모든 데이터를 쿼리하여 Python 환경으로 가져 온 후에 `groupby()` 함수를 수행하거나 새로운 `dictionary`를 만들어 메모리를 차지하는 것 보다는 데이터베이스의 메모리 및 인덱스를 고려하여 `GROUP BY` 쿼리를 정교하게 짜는 것이 부하가 훨씬 적은 방법이 될 수 있습니다.

데이터베이스를 사용하지 않을 경우에는 더할 나위 없이 좋은 함수인 것 같습니다.

## 1.16 Sequence 요소 필터링

#### Problem

`sequence` 내의 데이터에서 값을 추출하거나 어떤 규칙을 사용하여 `sequence`를 줄일 필요가 있습니다.

#### Solution

가장 쉬운 방법은 `sequence` 데이터를 `list comprehension`을 이용하여 필터링하는 것입니다.

```python
mylist = [1, 4, -5, 10, -7, 2, 3, -1]
print([n for n in mylist if n > 0])     # [1, 4, 10, 2, 3]
print([n for n in mylist if n < 0])     # [-5, -7, -1]
```

`list comprehension`을 사용하는 한가지 잠재적인 단점은 본래 입력이 크게 주어질 경우에 큰 결과가 만들어진다는 점입니다. 이를 고려하여 `generator` 표현식을 사용하여 필터링 된 값을 순회하는 결과를 만들어 낼 수 있습니다.

```python
pos = (n for n in mylist if n > 0)
for x in pos:
    print(x)                            # 1 4 10 2 3
```

때로는 필터링하는 기준이 `list comprehension` 또는 `generator` 표현식으로 쉽게 표현 될 수 없습니다. 예외처리나 기타 복잡한 세부 사항이 포함된 프로세스를 필터링한다고 하면 이를 위해 필터링 코드를 자체 함수에 넣고 `filter()` `built-in` 함수를 사용합니다.

```python
values = ['1', '2', '-3', '-' ,'4', 'N/A', '5']

def is_int(val):
    try:
        x = int(val)
        return True
    except ValueError:
        return False

ivals = list(filter(is_int, values))
print(ivals)        # ['1', '2', '-3', '4', '5']
```

`filter()`함수는 `iterator`를 생성하기 때문에 결과에 대한 `list`를 만들고 싶으면 위와 같이 `list()`를 사용해야 합니다.

#### Discussion

`list comprehension`과 `generator` 표현식은 간단한 데이터를 필터링하는 가장 쉽지만 가장 직접적인 방법일 때가 있습니다. 또한 동시에 데이터를 변환할 수 있다는 강력한 점이 있습니다.

```python
mylist = [1, 4, -5, 10, -7, 2, 3, -1]
import math
# [1.0, 2.0, 3.1622776601683795, 1.4142135623730951, 1.7320508075688772]
[math.sqrt(n) for n in mylist if n > 0]
```

필터링에 대한 한가지 변형은 기준에 미치지 못하는 값을 버리는 대신 새 값으로 바꾸는 것이 있습니다. 맞는 값을 찾기 보다 특정 범위 내의 잘못된 값을 제거하는 쪽으로 대신하고 싶을 경우가 있을 것입니다. 이는 다음과 같은 조건 표현으로 필터링 기준을 바꿈으로써 쉽게 해결할 수 있습니다.

```python
clip_neg = [n if n > 0 else for n in mylist]
print(clip_neg)     # [1, 4, 0, 10, 0, 2, 3, 0]
clip_pos = [n if n < 0 else for n in mylist]
print(clip_pos)     # [0, 0, -5, 0, -7, 0, 0, -1]
```

또 다른 주목할만한 필터링 도구로 `itertools.compress()`가 있는데 이는 iterable 객체 및 `boolean selector`를 input으로 갖습니다. 출력으로 `selector`의 해당 요소가 `True`가 되면서 iterable 객체의 모든 항목을 제공합니다. 이는 한 `sequence`를 관련된 다른 `sequence`로 필터링된 결과를 적용하려고 할 때 유용할 수 있습니다. 예를 들어 다음 데이터의 두 칼럼에서 

```python
address = [
    '5412 N CLARK',
    '5148 N CLARK',
    '5800 E 58TH',    
    '2122 N CLARK'    
    '5645 N RAVENSWOOD',    
    '1060 W ADDISON',    
    '4801 N BROADWAY',    
    '1039 W GRANVILLE', 
]

counts = [0, 3, 10, 4, 1, 7, 6, 1]
```

5보다 큰 `counts` 값에 대응되는 모든 주소의 `list`를 만들고 싶을 때 이렇게 할 수 있습니다.

```python
from itertools import compress
more5 = [n > 5 for n in counts]
print(more5)        # [False, False, True, False, False, True, True, False]
print(list(compress(address, more5)))   # ['5800 E 58TH', '4801 N BROADWAY', '1039 W GRANVILLE']
```

조건에 만족되는 요소를 가리키는 처음 생성한 `boolean sequence`가 이 열쇠입니다. `compress()` 함수는 그때 `True`값에 대응하는 항목을 선택하게 됩니다.

`filter()`처럼 `compress()` 역시 `iterator`를 일반적으로 반환합니다. 그러므로 `list`로 결과를 바꾸려면 `list()` 함수를 이용하여야 합니다.

#### Memo

`comprehension` 형식(특히 `set`)은 다음과 같은 수학적인 구조와 매우 흡사합니다.

```python
{ n for n in mylist if n > 0 }
```

$$\{ \ n \ | \ n \in mylist, \ n > 0 \ \}$$

## 1.17 Dictionary의 부분 집합을 추출

#### Problem

다른 `dictionary`의 부분집합인 `dictionary`를 만들고 싶습니다.

#### Solution

`dictionary comprehension`을 사용함으로써 이를 쉽게 해결할 수 있습니다.

```python
prices = {
    'ACME': 45.23,
    'AAPL': 612.78,
    'IBM': 205.55,
    'HPQ': 37.20,
    'FB': 10.75
}

# Make a dictionary of all prices over 200
p1 = {key:value for key, value in prices.items() if value > 200}

# Make a dictionary of tech stocks
tech_name = {'AAPL, 'IBM', 'HPQ', 'MSFT'}
p2 = {key:value for key, value in prices.items() if key in tech_name}
```

#### Discussion

`dictionary comprehension`으로 쉽게 해결할 수 있는 대부분은 `tuple`의 `sequence`를 만들고 `dict()` 함수를 통해 수행할 수 있습니다.

```python
p1 = dict((key, value) for key, value in prices.items() if value > 200)
```

하지만 `dictionary comprehension`로 해결하는 것이 조금 더 명확하고 실제로 훨씬 빠르게 실행됩니다. (무려 위의 예제에서 사용한 `prices dictionary`를 테스트했을 때는 두배 정도입니다.)

때론 같은 문제를 해결하기 위한 여러 방법이 있습니다. 예를 들어 두번째 예제는 이렇게 다시 쓸 수 있습니다.

```python
# Make a dictionary of tech stocks
tech_names = {'AAPL', 'IBM', 'HPQ', 'MSFT'}
p2 = {key:prices[key] for key in prices.keys() & tech_names}
```

그러나 시간을 재보면 처음 방법 보다 거의 1.6배 정도 느리게 나옵니다. 성능 문제가 중요하게 작용하면 일반적으로 약간의 시간을 들여 학습해야합니다. [14.13장]()에서 `timing`과 `profiling`에 대해 다룹니다. 

#### Memo

어떤 방법을 써서 실제로 테스트 했는지는 모르겠지만 `timeit` 모듈로 테스트 해본 결과가 실제로도 비슷하게 나왔습니다.

```python
from timeit import timeit

p1 = {key: value for key, value in prices.items() if value > 200}
p2 = dict((key, value) for key, value in prices.items() if value > 200)
p3 = {key: prices[key] for key in prices.keys() if prices[key] > 200}

print(timeit(lambda: p1))   # 0.4467564671541237
print(timeit(lambda: p2))   # 0.5706199682236008
print(timeit(lambda: p3))   # 0.48217073040558023
```

`{key: value}` 식의 `dictionary comprehension`이 확실히 좋아 보입니다. 하지만 실행 할 때마다 항상 빠른 것은 아닙니다.

[참고](//stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops?answertab=votes#tab-top)를 보시면 제가 테스트에서 사용한 `lambda`를 사용한 것에 대한 `stack frame` 오버헤드와 `p2`에서는 `(key, value)`라는 실제 `tuple`을 만드는 작업이 있으며 `p3`에서는 `price[key]`의 연산 과정을 거치는 반면에 `p1`에서는 어떤 구조를 생성하지 않고 바로 처리가 되어 빠르다 라고 언급하는 것 같습니다.

## 1.18 Sequence 요소에 이름 Mapping하기

#### Problem

`list`와 `tuple` 요소에 position으로 접근하는 코드를 가지고 있지만 때로는 코드를 읽기 다소 어렵게 만듭니다. 이런 요소에 이름으로 액세스하여 구조의 position에 덜 의존하고 싶을 것입니다.

#### Solution

`collections.namedtuple()`은 일반적인 `tuple` 객체 사용으로 최소한의 오버헤드만 주는 이점을 제공합니다. `collections.namedtuple()`은 실제로 Python의 `tuple` 타입의 서브 클래스를 반환하는 `factory method`입니다. 타입 이름과 필드가 그 이름을 가지면 그렇게 정의한 필드로 값을 전달하는 등 인스턴스화 할 수 있는 클래스를 반환하게됩니다.  

```python
from colections import namedtuple
Subscriber = namedtuple('Subscriber', ['addr', 'joined'])
sub = Subscriber('jonesy@example.com', '2012-10-19')
print(sub)          # Subscriber('jonesy@example.com', '2012-10-19')
print(sub.addr)     # 'jonesy@example.com'
print(sub.joined)   # '2012-10-19'
```

`namedtuple` 인스턴스가 일반적인 클래스 인스턴스로 보이시겠지만 `tuple`과 호환이 되며 `tuple` 에서 사용하는 `indexing`이나 `unpacking`같은 연산을 모두 지원합니다.

```python
print(len(sub))         # 2
addr, joined = sub
print(addr)             # 'jonesy@example.com'
print(joined)           # '2012-10-19'
```

`namedtuple`은 조작할 요소의 position으로부터 코드를 분리할 때 주로 사용합니다. 따라서 데이터베이스로부터 많은 `tuple`들의 `list`들을 얻게 되면, 해당 요소의 위치에 액세스함으로써 그것을 조작하게 됩니다. 일반적으로 코드를 짤때 만약 테이블에 새로운 컬럼이 추가되었을 경우에는 코드가 손상될 수가 있습니다. 하지만 반환된 `tuple`을 먼저 `namedtuple`로 캐스팅하는 경우에는 그렇지 않습니다.

```python
def compute_cost(records):
    total = 0.0
    for rec in records:
        total += rec[1] * rec[2]
    return total
```

해당요소의 위치를 참조하는 것은 종종 코드를 표현하기 어렵게 만들고 레코드의 구조에 좀 더 의존하게 됩니다. 다음은 `namedtuple` 버전입니다.

```python
from collections import namedtuple

Stock = namedtuple('Stock', ['name', 'shares', 'price'])

def compute_cost(records):
    total = 0.0
    for rec in records:
        s = Stock(*rec)
        total += s.shares * s.price
    return total
```

당연하게 예제의 `records sequence`가 이미 그러한 인스턴스에 포함되어 있을 때는 `Stock namedtuple`로의 명시적인 변환을 피할 수 있습니다.

#### Discussion

한가지 `namedtuple`의 사용 할 수 있는 방법 중 하나는 좀더 저장하기 위한 공간이 많이 필요한 `dictionary`를 대체할 때입니다. 그러므로 `dictionary`가 포함된 대용량 데이터 구조를 만들 때는 `namedtuple`을 사용하는 것이 좀 더 효율적일 것입니다. 반면에 `dictionary`와는 다르게 `namedtuple`은 `immutable`하다는 점을 주의하셔야 합니다.

```python
s = Stock('ACME', 100, 123.45)
print(s)        # Stock(name='ACME', shares=100, price=123.45)
s.shares = 75   # AttributeError: Can't set attribute
```

만약 속성을 다른 걸로 바꾸어야 한다면 특정 값만 바뀐 완전히 새로운 `namedtuple` 인스턴스를 만들어 주는 `_replace()` 메서드를 사용할 수 있습니다.

```python
s = s._replace(shares=75)
print(s)        # Stock(name='ACME', shares=75, price=123.45)
```

`_replace()` 메서드를 조금 사용하는건 선택적이거나 누락된 필드를 가진 `namedtuple`을 채우기 위한 편리한 방법이 될 수 있습니다. 이를 통해 기본 값을 포함하고 `_replace()`로 값이 대체된 새 인스턴스를 만드는 `tuple`의 프로토타입을 만들 수 있습니다.

```python
from collections import namedtuple

Stock = namedtuple('Stock', ['name', 'shares', 'price', 'date', 'time'])

# Create a prototype instance
stock_prototype = Stock('', 0, 0.0, None, None)

# Function to convert a dictionary to a Stock
def dict_to_stock(s):
    return stock_prototype._replace(**s)

a = {'name': 'ACME', 'shares': 100, 'price': 123.45}
print(dict_to_stock(a))     # Stock(name='ACME', shares=100, price=123.45, date=None, time=None)
b = {'name': 'ACME', 'shares': 100, 'price': 123.45, 'date': '12/17/2012'}
print(dict_to_stock(b))     # Stock(name='ACME', shares=100, price=123.45, date='12/17/2012', time=None)
```

마지막으로, 하지만 적어도 만약 목표가 다양한 인스턴스의 속성을 바꾸기 위한 효율적인 자료 구조를 정의하는 것이라면 `namedtuple`은 가장 좋은 선택은 아니라는 것을 아셔야 합니다. 대신에 클래스를 정의할 때 `__slots__`를 사용하는 것을 고려하시기 바랍니다. [8.4장 참조]()

#### Memo

디자인 패턴 중 하나인 Factory Method에 대한 가장 유명한 예시와 함께 비교해 보았습니다.

아래와 같이 객체를 직접 `new`를 통해 생성하지 않고 `PizzaFactory` 클래스의 `createPizza()`를 통해 생성하게 되며 이를 `namedtuple`을 통한 생성 방법과 비교한 것입니다.

Python 3 환경에서 실행하였습니다.

```python
class Pizza:
    HAM_MUSHROOM_TYPE = 0
    DELUXE_TYPE = 1
    SEAFOOD_TYPE = 2

    def __init__(self):
        self._price = None

    def getPrice(self):
        return self._price


class HamMushroomPizza(Pizza):
    def __init__(self, price):
        super().__init__()
        self._price = price


class DeluxePizza(Pizza):
    def __init__(self, price):
        super().__init__()
        self._price = price


class SeafoodPizza(Pizza):
    def __init__(self, price):
        super().__init__()
        self._price = price


class PizzaFactory:
    def createPizza(self, pizzaType, price):
        if pizzaType == Pizza.HAM_MUSHROOM_TYPE:
            return HamMushroomPizza(price)
        elif pizzaType == Pizza.DELUXE_TYPE:
            return DeluxePizza(price)
        elif pizzaType == Pizza.SEAFOOD_TYPE:
            return SeafoodPizza(price)


ham_mushroom = PizzaFactory().createPizza(Pizza.HAM_MUSHROOM_TYPE, 8.5)
deluxe = PizzaFactory().createPizza(Pizza.DELUXE_TYPE, 10.5)
seafood = PizzaFactory().createPizza(Pizza.SEAFOOD_TYPE, 11.5)

from collections import namedtuple

NamedPizzaFactory = namedtuple('NamedPizza', ['price'])
named_ham_mushroom = NamedPizzaFactory(8.5)
named_deluxe = NamedPizzaFactory(10.5)
named_seafood = NamedPizzaFactory(11.5)

assert ham_mushroom.getPrice() == named_ham_mushroom.price
assert deluxe.getPrice() == named_deluxe.price
assert seafood.getPrice() == named_seafood.price
```

## 1.19 데이터를 줄이는 동시에 변환하기

#### Problem

`sum()`, `min()`, `max()` 같은 데이터 수를 줄이는 함수를 실행하기 전에 데이터에 대한 필터링이나 변환이 먼저 필요한 경우

#### Solution

데이터를 축소 및 변환을 같이하는 하기 위한 매우 우아한 방법은 `generator`표현식 인수를 사용하는 것입니다. 예를 들어 사각형의 제곱을 계산하고 싶다면 다음과 같이 수행합니다.

```python
nums = [1, 2, 3, 4, 5]
s = sum(x * x for x in nums)
```

여기 다른 예제도 있습니다.

```python
# Determine if any .py files exist in a directory
import os
files = os.listdir('dirname')
if any(name.endswith('.py') for name in files):
    print('There be python!')
else:
    print('Sorry, no python.')

# Output a tuple as CSV
s = ('ACME', 50, 123.45)
print(','.join(str(x) for x in s))

# Data reduction across fields of a data structure
portfolio = [
    {'name': 'GOOG', 'shares': 50},
    {'name': 'YHOO', 'shares': 75},
    {'name': 'AOL', 'shares': 20},
    {'name': 'SCOX', 'shares': 65}
]
min_shares = min(s['shares'] for s in portfolio)
```

#### Discussion

solution은 하나의 인수가 함수에 제공될 때 `generator` 표현식의 약간의 구문론적인 측면을 보여줍니다.
(즉, 괄호의 반복이 필요없습니다.) 예를 들어 다음 두 문장은 같습니다

```python
s = sum((x * x for x in nums))  # Pass generator-expr as argument
s = sum(x * x for x in nums)    # More elegant syntax
```

`generator` 표현식을 사용하는 것은 때로는 처음에 임시 `list`를 만드는 것보다는 좀 더 효율적이고, 우아한 접근 방법입니다. 예를 들어 `generator` 표현식을 쓰지 않는다면  이런 구현을 고려할 것입니다.

```python
s = sum([x * x for x in nums])
```

이 역시 잘 동작하지만, 추가적인 단계를 도입하게되고 추가 `list` 역시 만들게 됩니다. 작은 `list`에 대해서는 중요하지 않을지도 모르지만 `nums`가 거대해지면 결국 한번만 사용하고 버리는 거대한 임시 자료구조를 만들게 됩니다. `generator`를 이용한 solution은 데이터를 순회하며 바꾸고 메모리 관리에도 더 효율적이게 됩니다. 

`min()`, `max()` 같은 특정한 감소 함수는 `generator`를 사용하려는 상황에서 유용할 수 있는 `key` 인수를 받습니다. 예를 들어 다음과 같이 대신 생각 할 수 있습니다.

```python
# Original: Returns 20
min_shares = min(s['shares'] for s in portfolio)

# Alternative: Returns {'name': 'AOL', 'shares': 20}
min_shares = min(portfolio, key=lambda s: s['shares'])
```

## 1.20 Combining Multiple Mappings into a Single Mapping

#### Problem

다중 `dictionary` 또는 `mapping`에서 값을 참조하거나 `key`의 존재성을 확인하는 방법 같이 특정 연산을 수행해서 논리적으로 단일 `mapping`으로 결합하려고 합니다.

#### Solution

다음 두 `dictionary`가 있습니다.

```python
a = {'x': 1, 'z': 3}
b = {'y': 2, 'z': 4}
```

이제 두 `dictionary` 모두 확인해야 하는 참조를 수행한다고 가정합니다.(a에서 먼저 검사되고 b는 찾지 못한 경우) 이를 위한 쉬운 방법은 `collections`모듈의 `ChainMap` 클래스를 사용하는 것입니다.

```python
from collections import ChainMap
c = ChainMap(a, b)
print(c['x'])       # 1 (from a)
print(c['y'])       # 2 (from b)
print(c['z'])       # 3 (from a)
```

#### Discussion

`ChainMap`은 다중 `mapping`을 취하고 논리적으로 하나의 `mapping`으로 만듭니다. 하지만 `mapping`이라는 말 그대로 합쳐지지는 않습니다. 대신에, `ChainMap`은 `mapping`에서의 `list`를 간단하게 유지하고 `list`를 스캔하기 위한 공통적인 `dictionary` 연산을 재정의합니다. 대부분 연산이 잘 동작합니다.

```python
print(len(c))           # 3
print(list(c.keys()))   # ['x', 'y', 'z']
print(list(c.values())) # [1, 2, 3]
```

중복된 `key`가 있으면 처음 `mapping`으로 얻은 `value`를 사용합니다. 그러므로 예제의 `c['z']` 항목은 `b`가 아니라 항상 `dictionary a`의 `value`를 참조하게 됩니다.

`mapping`을 변경하는 작업은 항상 첫 번째 `mapping`에만 영향을 줍니다. 예를 들면

```python
c['z'] = 10
c['w'] = 40
del c['x']
print(a)        # {'w': 40, 'z': 10}
del c['y']      # KeyError: "Key not found in the first mapping: 'y'"
```

`ChainMap`은 특히 프로그래밍 언어에서 `global` `local`등의 변수인 `scope`을 가진 `value`를 다룰 때 유용합니다. 사실 쉽게 만들 수 있는 메서드가 있습니다.

```python
values = ChainMap()
values['x'] = 1

# Add a new mapping
values = values.new_child()
values['x'] = 2

# Add a new mapping
values['x'] = 3
print(values)       # ChainMap({'x': 3}, {'x': 2}, {'x': 1})
print(values['x'])  # 3

# Discard last mapping
values = values.parents
print(values['x'])  # 2

# Discard last mapping
values = values.parents
print(values['x'])  # 1

print(values)       # ChainMap({'x': 1})
```

`ChainMap`의 대안으로는 `dictionary`를 `update()` 메서드를 사용하여 합치는 방법을 생각해 볼 수 있습니다.

```python
a = {'x': 1, 'z': 3}
b = {'y': 2, 'z': 4}
merged = dict(b)
merged.update(a)
print(merged['x'])  # 1
print(merged['y'])  # 2
print(merged['z'])  # 3
```

이 역시 동작하지만, 완전히 분리된 `dictionary` 객체를 만들어야 합니다.(또는 기존의 `dictionary` 중 하나를 파괴하듯이 바꿉니다) 또한 원본 `dictionary` 중 하나라도 변경되면 합쳐진 `dictionary`에 반영이 되지 않습니다.

```python
a['x'] = 13
merged['x']         # 1
```

`ChainMap`은 원본 `dictionary`를 사용하기 때문에 이런 결과가 나오지 않습니다.

```python
a = {'x': 1, 'z': 3}
b = {'y': 2, 'z': 4}
merged = ChainMap(a, b)
merged['x']
a['x'] = 42
merged['x']         # 42 Notice change to merged dicts
```